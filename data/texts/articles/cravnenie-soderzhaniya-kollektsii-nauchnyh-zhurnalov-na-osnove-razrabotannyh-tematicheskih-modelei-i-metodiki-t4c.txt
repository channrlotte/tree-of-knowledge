Cloud of Science. 2019. T. 6. № 3 http://cloudofscience.ru
Сравнение содержания коллекций научных журналов на основе разработанных тематических моделей и методики T4C
Ф. В. Краснов*, М. М. Хасанов*, А. В. Диментов**, М. Е. Шварцман**
*ООО «Газпромнефть НТЦ» 190000, Санкт-Петербург, наб. реки Мойки, д. 75-79, литер Д
**Национальный электронно-информационный консорциум 115114, Москва, ул. Летниковская, д. 4, стр. 5
e-mail: [email protected]
Аннотация. Каждое научное издание озабочено своей контентной аутентичностью. Но субъективное понимание тематической ниши главным редактором издания может существенно отличаться от реального положения дел. Журнал может дублировать другое издание по научным направлениям, а может не соответствовать собственным, декларированным направлениям. Журналы, издаваемые десятилетиями, проходят естественные фазы жизненного цикла: старение и деградацию. В результате приоритеты научного издания могут мигрировать до диаметрально противоположных. Например, вместо академических статей по математической логике большинство статей окажется посвящено популяризации олимпиад по математике для студентов. Помимо тематического наполнения журнала, важно и сообщество авторов. С течением времени критерии попадания в номер для авторов начинают отличаться. Возникает определенное неравенство. Например, зрелому автору публиковаться первый раз в данном журнале сложнее, чем аспиранту известного профессора. Здоровая экосистема журнала обладает характерным поведением и находится в согласии с динамикой научного контента. Проблема своевременного обнаружения вышеперечисленных симптомов дисгармонизации жизненно важна для редакционных коллегий журнала. Гомеостаз читаемости и цитируемости позволяет установить стабильные метрики развития журнала. Но такая статистика не всегда бывает доступна в отличии от текстов статей. Авторы разработали методический подход для сравнительного анализа контента журналов с целью выявления степени соответствия контента декларируемым научным направлениям. Одной из составляющей этой методики, названной авторами T4C, является возможность обнаружения аномального поведения экосистемы журнала, выявления коммерциализации научного контента, гостевых соавторов, самоцитирования, «выкупленных выпусков» и других отклонений. Предложенный авторами подход основан на методологии тематического моделирования и теории графов. Научная новизна методики T4C состоит в новых метриках парного модального тематического моделирования с последовательной регуляризацией. В результате
проведенного в настоящей работе эксперимента было показано, что разработанная авторами методика T4C продуктивно работает на коллекциях слабо структурированных научных текстов на английском языке. Ключевые слова: тематическое моделирование, классификация текстов, BigARTM, PLSA, RandomForest
1. Введение
Согласно информации в отчете о развитии искусственного интеллекта1 количество статей по этому научному направлению выросло до 140 тысяч в год (рис. 1).
Рисунок 1. Динамика роста количества статей по направлению «Искусственный интеллект»
Вряд ли существует ученый, который поддерживает свое понимание развития этой научной области, читая все статьи. Для анализа таких массивов информации используются автоматизированные средства обработки текстов.
Одним из наиболее популярных методов анализа текстов является тематическое моделирование.
Сравнительный анализ контента относится к области информационного поиска и ранжирования. Для поиска определенных фраз в корпусе документов производится ранжирование контента для выделения документа с наивысшим рангом.
Задачи сравнения «документ-документ» нашли широкое применение в области поиска плагиата [1, 2].
В настоящем исследовании авторами ставится задача сравнения корпусов документов: «корпус-корпус». Статистические подходы к решению этой задачи были сделаны в работах [3, 4]. Современное развитие статистических подходов для этнической стратификации корпусов текстов изучено в работе [5]. В исследовании [6] сделано статистическое профилирование корпусов текстов для их сравнения.
1 https://syncedreview.com/tag/2018-china-ai-development-report/
Ф. В. Краснов, М. М. Хасанов, А. В. Диментов, М. Е. Шварцман
Сравнение корпусов с помощью извлечения тематик и введение метрик было изучено в работах [7, 8].
Другим возможным подходом может быть построение корреляционной матрицы «документ-документ» и сведение к задаче сравнения документов. В этом случае размерность корреляционной матрицы будет N х N2, где N — это количество документов. В корпусы может входить разное количество документов, поэтому в общем случае N = N •
2. Методика
Наиболее современным подходом к задаче выявления тематик, на взгляд авторов, является метод аддитивной регуляризации для стохастических матриц, изложенный в работе [9]. Тематическое моделирование — это одно из направлений автоматизированного анализа текстов, призванное выявить, к каким темам относится каждый из документов коллекции и какими терминами определяется та или иная тема. Таким образом, на входе исследователем подается коллекция текстов, а на выходе мы получаем тематики (с набором слов для каждой из тематик), на основе которых может быть проведена кластеризация коллекции текстов. Тема в данном случае — это результат би-кластеризации, т. е. одновременной кластеризации слов и документов по их семантической близости [10].
Важной задачей, реализуемой в рамках тематического моделирования, является также задача снижения размерности, потому что число тем значительно меньше числа слов в документах. Тематическое моделирование — это популярный инструмент анализа текстовой информации, реализованный в таких широко используемых библиотеках, как Gensim [11]. В работе [12] приведено сравнение быстродействия различных программных реализаций построения тематических моделей.
Инструментарий тематического моделирования используется для изучения массивов данных научных публикаций и определения трендов развития того или иного научного направления [13], анализа новостных потоков [14] и информационного поиска [15].
Как отмечается Коршуновым и Гомзиным [10], переход из пространства терминов (так называют преобразованные определенным образом слова) в пространство найденных тематик позволяет разрешать проблемы синонимии и полисинонимии терминов. Благодаря автоматическому анализу текстов становится решаемой задача реферирования и систематизации сверхбольших коллекций текстов, состоящих из миллиардов документов. Но также уверенно тематические модели работают и для средних, и маленьких коллекций. Большинство моделей разрабатывается на основе латентного размещения Дирихле (Latent Dirichlet Allocation, далее —
LDA) [16]. Эта модель объясняет присутствие одинаковых слов в различных документах тем, что документы посвящены одной тематике (т. е. могут быть отнесены к латентной группе). На взгляд авторов, более перспективным подходом к моделированию тем является PLSA [17] за счет использования регуляризации при построении модели. Развитием PLSA, но уже с множественной регуляризацией является ARTM [9], примененный авторами данного исследования.
Авторы поставили задачу использовать наиболее современные разработки в области тематического моделирования и сделать их доработку, позволяющую применять тематическое моделирование для задач сравнительного анализа корпусов текстов.
Сформулируем две гипотезы.
Гипотеза о существовании тематик. Каждое вхождение термина w в научную статью d связано с тематикой t из заданного множества T.
Гипотеза об условной независимости тематик. Появление терминов w в документе d по тематике t не зависит от документа d, а зависит только от t и может быть описано единым распределением p(w |t) = p(w | d, t).
Пусть W— это множество всех слов коллекции документов D = (d0,..., d ). Обозначим условную вероятность появления термина w в документе d, как p(w | d ). Тогда по теореме о полной вероятности будет верно следующее выражение (1):
p(w | d) = X p(w | d, t)p(t | d) = X p(w | t)p(t | d) = X Qd,	(1)
teT	tel	teT
где qwt = p(w 11) — вероятность термина w в тематике t e T, а 9id = p(t | d) — вероятность тематики t в документе d. Уравнение (1) можно представить в графическом виде (рис. 2).
ш
d	D
Рисунок 2. Иллюстрация уравнения (1)
Матричное разложение P = Фх0 имеет бесконечное множество решений: P = çpx© = (çpxS)x (S-1 х 0) = Ф х 0, где Ô = OxS и 0 = S"1 х0.
Ф. В. Краснов, М. М. Хасанов, А. В. Диментов, М. Е. Шварцман
Для получения приближенного решения уравнения (1) использовался механизм минимизации кросс-энтропии. Чтобы получить матрицы Ф и © с определенными свойствами в процесс оптимизации добавляются регуляризационные слагаемые.
Методический каркас исследования (методика Т4С) представлен на рис. 3.
Рисунок 3. Методика Т4С — методический каркас исследования
Мультимодальная тематическая модель строит распределения тем на терминах
11), авторах р(а | £), метках времени р(у 11), связанных документах р(й 11), рекламных баннерах р(Ь | £), пользователях р(и 11) и объединяет все эти модальности в одну тематическую модель. Модальный подход к обучению тематической модели позволяет проводить единое обучение, а потом рассматривать матрицу 0 для различных значений одной из модальностей. Например, 9(М1 | V) будет содержать только распределение тематик по документам, относящимся к модальности М1 со значением V. Важно отметить, что при этом матрица Ф является общей для всех документов.
На рис. 4 приведен пример матриц 0 для разных значений модальности, показывающий, как могут выглядеть плотности для тематик. Мы видим, что для тематик Т и Т4 плотности для разных значений модальности Ых могут визуально похожи, а для тематик Т2 и Т2 плотности визуально могут отличаться. Представленная на рис. 4 схема позволяет визуально оценить степень похожести двух коллекций документов с помощью модальной тематической модели. На количественном уровне определить степень похожести можно, проведя классификацию значений модальности по матрице 0. Вектора со значениями вероятностей тематик для каж-
дого документа могут быть разбиты на обучающую и тестовую выборку для обучения классификатора определять метки значений модальности.
Рисунок 4. Пример матриц 9 для разных значений модальности М
Возвращаясь к задаче обучения тематической модели, важно отметить, что оно сводится к максимизации логарифма правдоподобия Ь(Ф, ©) с дополнительными аддитивными регуляризаторами Д(Ф, ©):
Ь (Ф, ©) = п* 1п
Ь(Ф, ©) + Б(и, Ф, ©) ^ тах,
ф,®
Ф, ©) = Е»А (Ф, ©).
(2)
(3)
(4)
Слагаемое Ф, ©) в уравнении (4) представляет суперпозицию применяемых регуляризаторов Я с весами . А п^ — это количество повторений слова w в документе d.
Оптимизационная задача (3) не может быть решена градиентными методами, так как функционал Ь(Ф, ©) в общем случае не является дифференцируемым. Поэтому для нахождения Ф и © используется двухступенчатый подход к оптимизации, называемый ЕМ-алгоритмом. Формальное изменение ЕМ-алгоритма при применении модальностей может быть записано следующим образом.
Е-шаг:
Раы, =11 ФА Пег .	(5)
М-шаг:
Ф^ =
+ Ф^
дД
дФп
(6)
Ф. В. Краснов, М. М. Хасанов, А. В. Диментов, М. Е. Шварцман
где nw, = Z ndwPtdw;
d eD
> nd = Z ndwP,dW	(7)
weW
На E-шаге производится инициация §wt и %td и вычисляется вероятность тройки значений piAl,. На М-шаге по значениям piAl, вычисляются новые значения Ф™« и 9irf. И так процесс продолжается до достижения сходимости.
3. Эксперимент
Для экспериментального подтверждения предложенной методики T4C (1) авторами была выбрана коллекция патентов [18]. Патент так же, как и научная статья, является слабо структурированным документом. Патент обладает следующими формализованными полями: название, описание, автор, страна, дата. Для исследования были выбраны 9992 патента из Китая (CN) и 22502 из США (US). Для выбора использовалось ключевое слово seism. Таким образом, на входе было две коллекции документов по направлению сейсмика.
Размерность словаря получившейся коллекции составляет 16 млн единиц. В словарь входят биграмы. Представление текста в виде биграммной вероятностной модели выбрано для более емкой передачи смыслов. Для уменьшения редко встречаемых слов были выбраны фильтры: минимальная частота слова более 4 и максимальное количество документов, в которых встречается слово не более 40% от общего количества документов. После фильтрации словарь составил 4 млн единиц.
Для проверки гипотезы о классификации нам нужно вычислить точность, с которой документ может быть отнесен к своей коллекции. Для этого авторы использовали подход на основе «мешка слов» (Bag of Words, BoF). Для частотного анализа была применена библиотека sklearn. В качестве начальной оценки авторы применили классификатор на основе алгоритма Байеса [19]. Так как метки для классификации представлены в коллекциях неравномерно, то при разделении набора данных на обучающий и тестируемый была использована стратификация. Для подготовки признаков (features) использовался конвеер (pipiline) для трансформации текста в частоты терминов и коэффициенты TF-IDF: pipeline =
Pipeline([ ('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', naive_bayes.ComplementNB()), ])
®td =
8R
8a7
В результате обучения модель показала точность (Accuracy), равную 97.5% на отложенной выборке с размером 0.3 от всей выборки. Такая высокая точность классификации означает, что каждый документ очень характерен для своей коллекции. Китайский патент по составу текста описания заявки принципиально отличается от американского патента.
Содержание патентов не должно повторяться со временем. Суть научной разработки в том, чтобы предлагать что-то новое. Поэтому в рамках методики T4C авторы проверили, насколько точно классифицируются патенты по годам для двух коллекций. Распределение патентов по годам представлено на рис. 5.
Рисунок 5. Гистограмма распределения коллекции по годам
Для проверки гипотезы о миграции контента во времени был использован тот же конвеер. В результате патенты, сделанные до 2004 г., отличаются от патентов, сделанных в 2010 г. с точностью 85% и 67% (С№).
Следующим шагом была построена модальная тематическая модель. На рис. 6 отображены качественные характеристики (метрики «Контраст» и «Чистота» ядра тематик) обучения тематической модели, показывающие, что сходимость достигнута.
В качестве модальностей были выбраны текст описания, страна и год. Веса модальностей были подобраны в соответствии с методикой, описанной в работе [20] и составили 1:3:3. Количество тематик модели также является свободным параметром. С помощью методики, разработанной авторами в работе [21], было определено, что для данной коллекции достаточно 30 тематик.
На рис. 7 представлена матрица 9, описывающая распределения вероятностей в координатах «тематика-документ» для каждой страны.
Ф. В. Краснов, М. М. Хасанов, А. В. Диментов, М. Е. Шварцман
О	2	4	6	8	10	12	14
Количество проходов по коллекции.
Рисунок 6. Метрики качества обучения тематической модели
Матрица вtCOUNTRY^CNi
Матрица 0(СО1Л\/ТДУ|и5)
ми I IIIИШЫ.ШП1П 1Ш1
2000 4000	6000	ВООО
номер документа
5000	10000	15000	20000
номер документа
Рисунок 7. Распределение «тематика-документ» для обоих коллекций
С помощью рис. 7 авторы провели визуальный анализ распределений «тематика-документ» (0Й) для различных тематик. Полосы на рисунке соответствуют тематикам, которые имеют большие вероятности для многих документов. Для китайских патентов это тематики, представленные следующими термами из матрицы Ф (табл. 1).
Для тематик американских патентов нет таких характерных полос. Это означает, что выделенные тематики распределены более равномерно. В табл. 2 показаны тематики американских патентов с высокими вероятностями.
Для дальнейших шагов эксперимента важно отметить, что из пяти тематик, приведенных в табл. 1 и 2, тематики sbj20 и sbj8 являются важными для обоих коллекций, остальные тематики отличаются.
Таблица 1. Тематики китайских патентов с высокими вероятностями
nz1	sbj26	sbj20	sbj22	sbj8
earthquake	polymer	spring	wave	user
model	fiber	plate	phase	communication
implementation	resin	mass	vibration	network
steel	weight	axis	response	node
carry	layer	tube	mass	module
utility	composition	vibration	transducer	sensor
plate	temperature	contact	detector	computer
Таблица 2. Тематики американских патентов с высокими вероятностями
sbj6	sbj25	sbj3	sbj20	sbj8
member	trace	output	spring	user
panel	seismic_data	input	plate	communication
plate	receiver	filter	mass	network
assembly	velocity	circuit	axis	node
frame	survey	digital	tube	module
building	reflection	pulse	vibration	sensor
structural	equation	block	contact	computer
Для более точного определения степени тематического пересечения авторами в рамках методики T4C была рассчитана точность классификации патентов по матрице 0. Значение метрики Accuracy было вычислено с помощью метода RandomForest и получилось 65%. Оптимальные параметры метода RandomForest были подобраны с помощью поиска по сетке (GridSearch) с осреднением по 5 прогонам и составили: количество эстиматоров — 200, максимальная глубина дерева — 5. Полученный результат согласуется с визуальными наблюдениями матриц 0, сделанными на основании рис. 7. Действительно, из визуального наблюдения видно, что распределение тематик по документам для каждой из меток (CN, US) недостаточно различается, чтобы точность классификации была высокой.
4. Заключение
Для исследования выбрана одна из актуальных задач из области управления научным контентом. Процессы контроля качества и управления содержанием научного журнала представляют важное направление деятельности для редакционных колле-
Ф. В. Краснов, М. М. Хасанов, А. В. Диментов, М. Е. Шварцман
гий. Существует множество факторов, влияющих на контент научного журнала. Авторами в работе выделены факторы жизненного цикла и научной экосистемы.
Предложенная методика T4C является удобным подручным инструментом для выявления глубинных свойств коллекций текстов. Отличительная особенность методики T4C состоит в том, что она позволяет сравнивать коллекции текстов.
Для проверки методики T4C авторами был выбран экспериментальный подход. Минимально необходимые аналитические выкладки сделаны авторами в разделе, описывающем методику T4C. В настоящей работе авторами приведено экспериментальное подтверждение методики в части гипотезы о классификации и модальной тематической модели. Метрики, связанные с авторами, в данном эксперименте не вычислялись.
Патенты являются хорошим аналогом научных статей, имеют четкую временную динамику и языковые особенности. А в смысле временной миграции контента должны вести себя лучше научных статей. Кроме того, в результате эксперимента было выяснено, что тексты заявок на патенты содержат культурные особенности.
В результате применения T4C к коллекции слабо структурированных текстов были получены следующие результаты:
1.	Гипотеза о классификации подтверждена с точностью 97.5%. Китайский (американский) патент может быть идентифицирован с указанной точностью на основании текста описания. Анализ величин коэффициентов модели позволяет сделать заключение о характерных особенностях описаний. Американские патенты содержат больше картинок, что отражает визуальную национальную особенность. Китайские патенты содержат больше шумовых тематик (опечаток, редких идиом, устаревших оборотов).
2.	Тематическая однородность оценена визуально, с помощью карт «тематика-документ» для выборки американских и китайских патентов.
3.	Метрика тематической чистоты (Purity) 6 показывает, что разработанная авторами последовательность регуляризации позволяет выделять шумовые и основные тематики.
4.	Классификация коллекций тематик по странам (CN, US) позволяет достичь точности 60%, что находится в согласии с визуальной оценкой.
5.	Корреляции между патентами из разных лет (2010 vs. < 2004) составляют 85% и 67% для американских и китайских патентов, соответственно. Данный факт показывает эволюцию патентных заявок во времени. И может качественно характеризовать скорость изменений.
6.	Визуальная оценка слов с наибольшим весом из разных лет согласуется с вычисленными значениями корреляции.
На основании проведенного эксперимента авторы сделали следующие качественные выводы и наблюдения:
-	обучение модели с весами модальностей (1:3:3) позволяет сделать заключение о характерных научных направлениях для каждой страны;
-	для Китая наибольшую значимость имеют патенты, направленные на изучение землетрясений;
-	для Америки патентование в области сейсмики идет более равномерно по всем тематикам.
Разработанная методика T4C может быть применена для решения бизнес-задач по сравнению коллекций слабо структурированных текстов.
Литература
[1]	Pawelczak D. Benefits and drawbacks of source code plagiarism detection in engineering education // 2018 IEEE Global Engineering Education Conference (EDUCON). — IEEE, 2018. P. 1048-1056.
[2]	Jack F. Study on the Different Forms of Plagiarism in Textual Data and Image: Internal and External Detection // In book: Advanced Metaheuristic Methods in Big Data Retrieval and Analytics. — IGI Global, 2019. P. 75-90.
[3]	Rayson P., Garside R. Comparing corpora using frequency profiling // Proceedings of the workshop on Comparing corpora WCC'00. — Association for Computational Linguistics, 2000. Vol. 9. P. 1-6.
[4]	Bharati A., Rao K. P., Sangal R., & Bendre S. M. Basic statistical analysis of corpus and cross comparison among corpora // Technical Report. — Indian Institute of Information Technology, 2000.
[5]	Hodler R., Srisuma S., Vesperoni A., & Zurlinden N. Measuring Ethnic Stratification and its Effect on Trust in Africa // CESifo Working Paper. 2018. No. 7405. (https://ssrn.com/abstract=3338759)
[6]	Rayson P. Matrix: A statistical method and software tool for linguistic analysis through corpus comparison // Thesis. — Lancaster University, 2003.
[7]	Marin Perez M. J. Measuring the degree of specialisation of sub-technical legal terms through corpus comparison // Terminology. International Journal of Theoretical and Applied Issues in Specialized Communication. 2016. Vol. 22. No. 1. P. 80-102.
[8]	Mihwa Chung T. A corpus comparison approach for terminology extraction // Terminology. International Journal of Theoretical and Applied Issues in Specialized Communication. 2003. Vol. 9. No. 2. P. 221-246.
[9]	Vorontsov K., Potapenko A. Additive regularization of topic models // Machine Learning, 2015. Vol. 101. No. 1-3. P. 303-323.
[10]	Коршунов А., Гомзин А. Тематическое моделирование текстов на естественном языке // Труды Института системного программирования РАН. 2012. № 23. С. 215-244.
Ф. В. Краснов, М. М. Хасанов, А. В. Диментов, М. Е. Шварцман
[11]RehurekR.,	Sojka P. Gensim — statistical semantics in Python // EuroScipy 2011 (Paris, 2528 August 2011). — 2011. (https://www.fi.muni.cz/usr/sojka/posters/rehurek-sojka-scipy2011.pdf)
[12]	Vorontsov K., Frei O., Apishev M., Romov P., Dudarenko M. BigARTM: open source library for regularized multimodal topic modeling of large collections // International Conference on Analysis of Images, Social Networks and Texts. — Springer. 2015. P. 370-381.
[13]	Blei D. M., Lafferty J. D. Dynamic topic models // Proceedings of the 23rd international conference on Machine learning. — ACM, 2006. P. 113-120.
[14]	Zhao W. X., Jiang J., Weng J., He J., Lim E. P., Yan H., и Li X. Comparing twitter and traditional media using topic models // European conference on information retrieval. — Springer, 2011. P. 338-349.
[15]	Ponte J. M., Croft W. B. A language modeling approach to information retrieval // SIGIR '98 Proceedings of the 21st annual int. ACM SIGIR conf. on Research and development in information retrieval. — ACM, 1998. P. 275-281. (https://doi.org/10.1145/290941.291008)
[16]	Blei D. M., Ng A. Y., Jordan M. I. Latent dirichlet allocation // Journal of machine Learning research. 2003. No. 3. Jan. P. 993-1022.
[17]	Mei Q., Cai D., Zhang D., & Zhai C. Topic modeling with network regularization // Proceedings of the 17th international conference on World Wide Web. ACM. 2008. P. 101-110.
[18]	Krasnov F. Seismic Patents (BoW). 2019. (https://doi.org/10.5281/zenodo.3336144)
[19]Rennie	J. D., Shih L., Teevan J., & Karger D. R. Tackling the poor assumptions of naive bayes text classifiers // Proceedings of the 20th international conference on machine learning (ICML-03). — 2003. P. 616-623.
[20]Ianina	A., Golitsyn L., Vorontsov K. Multi-objective topic modeling for exploratory search in tech news // Conference on Artificial Intelligence and Natural Language. — Springer, 2017. P. 181-193.
[21]	Krasnov F., Sen A. The Number of Topics Optimization: Clustering Approach // Machine Learning and Knowledge Extraction. 2019. Vol. 1. No. 1. P. 416-426.
Авторы:
Федор Владимирович Краснов — кандидат технических наук, ведущий эксперт, НТЦ Газ-промнефть
Марс Магнавиевич Хасанов — доктор технических наук, генеральный директор, Газпром-нефть НТЦ
Александр Владимирович Диментов — эксперт, Национальный электронно-информационный консорциум
Михаил Ефремович Шварцман — заместитель директора, Национальный электронно-информационный консорциум
Methodology for Comparing Text Corpora via Topic Model
F. V. Krasnov*, M. M. Khasanov*, A. V. Dimentov", M. E. Shvartsman"
*Gazpromneft STC, 75-79 liter D, Moyka River emb., St Petersburg, Russia 190000 "NEICON, b.4/5 Letnikovskaia St. Moscow 115114 e-mail: [email protected]
Abstract. The authors of this paper developed a methodology approach for comparative analysis of patents' content. The approach named T4C is based on the topic modeling methodology and the machine learning methodology. Scientific novelty of the T4C technique consists in new metrics for pair modal topic modeling with additive regularization. The authors were able to identify the ownership of a patent in a particular country with an accuracy of 97.5% using machine learning methods with a teacher. When studying the dependence of patents on time, the authors were able to identify the patent belonging to a specific period with an accuracy of 85% for a specific country. The authors have developed a visual presentation of a thematic correlation between groups of patents. It should also be noted that in terms of the patent description text composition, Chinese patents are fundamentally different from US patents. According to results of the experiment described in this paper, the T4C proved to be productive for poorly structured medium-sized collections of scientific texts in English. The results presented in this study were used to manage the patenting process at GazpromNeft STC. Keywords: topic modeling, text classification, BigARTM, PLSA, RandomForest.
References
[1]	Pawelczak D. (2018) Benefits and drawbacks of source code plagiarism detection in engineering education. In 2018 IEEE Global Engineering Education Conference (EDUCON). P. 1048-1056.
[2]	Jack F. (2019) Study on the Different Forms of Plagiarism in Textual Data and Image: Internal and External Detection. In book: Advanced Metaheuristic Methods in Big Data Retrieval and Analytics. IGI Global. P. 75-90.
[3]	Rayson P., Garside R. (2000) Comparing corpora using frequency profiling. In Proceedings of the workshop on Comparing corpora. Vol. 9. P. 1 -6.
[4]	Bharati A., Rao K. P., Sangal R., & Bendre S. M. (2000) Basic statistical analysis of corpus and cross comparison among corpora. Technical Report of Indian Institute of Information Technology.
[5]	Hodler R., Srisuma S., Vesperoni A., & Zurlinden N. (2018) CESifo Working Paper No. 7405. (https://ssrn.com/abstract=3338759)
[6]	Rayson P. Matrix: (2003) A statistical method and software tool for linguistic analysis through corpus comparison. Thesis. Lancaster University.
[7]	Marin Perez M. J. (2016) Terminology. International Journal of Theoretical and Applied Issues in Specialized Communication, 22(1):80-102.
[8]	Mihwa Chung T. (2003) Terminology. International Journal of Theoretical and Applied Issues in Specialized Communication, 9(2):221-246.
[9]	Vorontsov K., Potapenko A. (2015)Machine Learning, 101(1-3):303-323.
[10]	Korshunov A., Gomzin A. (2012) Trudy Instituta sistemnogo programmirovaniya RAN, (23):215-244. [In Rus]
[11]	Rehurek R. & Sojka P. (2011) Gensim — statistical semantics in python. In EuroScipy.
[12]	Vorontsov K. et.al. (2015) BigARTM: open source library for regularized multimodal topic modeling of large collections. In International Conference on Analysis of Images, Social Networks and Texts. P. 370-381.
[13]	Blei D. M. & Lafferty J. D. (2006) Dynamic topic models. In Proceedings of the 23rd international conference on Machine learning. P. 113-120.
[14]	Zhao W. X., Jiang J., Weng J., He J., Lim E. P., Yan H., & Li X. (2011) Comparing twitter and traditional media using topic models. In European conference on information retrieval. P. 338-349.
Ф. В. Краснов, М. М. Хасанов, А. В. Диментов,
М. Е. Шварцман
[15]	Ponte J. M. & Croft W. B. (1998) A language modeling approach to information retrieval. In SIGIR '98 Proceedings of the 21st annual int. In ACM SIGIR conf. on Research and development in information retrieval. P. 275-281. https://doi.org/10.1145/290941.291008
[16]	BleiD. M., Ng A. Y. & Jordan M. I. (2003) Journal of machine Learning research, 3:993-1022.
[17]	Mei Q., Cai D., Zhang D., & Zhai C. (2008)Topic modeling with network regularization. In Proceedings of the 17th international conference on World Wide Web. P. 101 -110.
[18]	Krasnov F. (2019) Seismic Patents (BoW). http://dx. doi.org/10.17632/x5z5r6br2z.1
[19]	Rennie J. D., Shih L., Teevan J., & Karger D. R (2003) Tackling the poor assumptions of naive bayes text classifiers. In Proceedings of the 20th international conference on machine learning (ICML-03). P. 616-623.
[20]	Ianina A., Golitsyn L., Vorontsov K. (2017) Multi-objective topic modeling for exploratory search in tech news. In Conference on Artificial Intelligence and Natural Language. P. 181-193.
[21]	Krasnov F., Sen A. (2019) Machine Learning and Knowledge Extraction, 1(1):416-426.
