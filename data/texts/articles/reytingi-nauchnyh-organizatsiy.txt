УНИВЕРСИТЕТЫ И РЕЙТИНГИ
Максим Андреевич Юревич
младший научный сотрудник, Центр макроэкономических исследований Финансового университета при Правительстве РФ,
Москва, Россия e-mail: [email protected]
УДК: 001.38
DOI: 10.24411/2079-0910-2018-10021
Рейтинги научных организаций1
Рейтинги университетов, научных журналов и ученых пользуются большой популярностью как в среде научно-образовательного сообщества, так и у администраторов научно-исследовательской деятельности. Рейтинги научных организаций пока не столь распространены, хотя с каждым годом в разных странах предпринимаются все новые попытки их построения. В данной статье рассмотрены три основных подкласса рейтингов научных организаций: глобальные, отраслевые и вебометрические. В целом набор используемых переменных и методов их обработки или усреднения почти идентичен их перечню при ранжировании университетов. Преимущественно применяются показатели публикационной и патентной активности, финансовой результативности, а также представленности в интерактивной среде. Как следует из проведенного анализа, разработчики рейтингов зачастую не стремятся сформировать итоговый табель организаций, выполняющих исследования и разработки, а предлагают пользователю ресурса самостоятельно подобрать конфигурацию сортировки и получить пер-сонализирвоанный рейтинг. Эта особенность открывает широкие возможности перед учеными-науковедами для изучения деятельности научных учреждений, выявления предпосылок и проблем продвижения организаций в созданных рейтингах. В заключительной части работы описаны уже проведенные исследования глобального научного ландшафта при помощи наиболее известного из всех рейтингов научных учреждений Scimago Institutions Rankings. Успешные попытки идентификации специфических характеристик частных исследовательских компаний, узкоспециализированных научных учреждений сквозь призму рейтинга подтверждают их высокий аналитический потенциал. Кроме того, разработанный методологический арсенал зарубежных и российских рейтингов может оказаться крайне полезен для доработки системы оценки и мониторинга результативности деятельности научных учреждений. Ключевые слова: рейтинги, научные организации, наукометрия, вебометрия, научная политика.
1 Статья подготовлена в рамках Государственного задания Правительства РФ Финансовому университету на 2018 год (тема «Оценка деятельности научных учреждений, подведомственных ФАНО России», шифр: АААА-А18-118052490088-4).
В отличие от рейтингов университетов, вызывающих интерес государственных регуляторов и пользующихся спросом со стороны абитуриентов и, видимо, преподавателей [Балацкий, Екимова, 2012; Николенко, Федорова, 2017] с целью выявления лучшего места для обучения или трудоустройства соответственно, рейтинги научных организаций не столь популярны в России и за рубежом. Значительно меньшая численность таких учреждений по сравнению с университетами как в России, так и за рубежом обуславливает ограниченность аудитории подобного продукта, который едва ли может быть востребован за пределами научного сообщества, да и многими членами последнего. Тем не менее представители крупных аналитических компаний и научные коллективы периодически разрабатывают способы ранжирования научно-исследовательских организаций, используя библиометрическую информацию, представленность такого учреждения в интерактивном пространстве или экспертные оценки. Важно отметить, что практическая сфера применения подобных рейтинговых продуктов пока отчетливо не просматривается. Эти рейтинги пока не используются при оценке деятельности организаций и не служат ориентирами реализации государственной политики (как, например, рейтинги вузов в Госпрограмме «5—100»), а скорее выступают в качестве инструмента исследований ландшафта мировой науки.
Вместе с тем российский опыт оценки учреждений в рамках Федеральной системы мониторинга результативности деятельности научных организаций, выполняющих научно-исследовательские, опытно-конструкторские и технологические работы (ФСМНО), так же как и зарубежная практика, показывает, что существует потребность в рейтингах как исходной позиции для экспертного анализа и последующего вынесения административного суждения. Принимая во внимание шквал критики в адрес наукометрической компоненты ФСМНО [например, Гуськов, Косяков, Селиванова, 2018], накопленные приемы ранжирования исследовательских учреждений (в особенности за рубежом) могут способствовать разрешению отмечаемых научных сообществом проблем.
Глобальные рейтинги научных организаций
Наиболее известный из всех рейтингов научных организаций — Scimago Institutions Rankings2 (SIR), который основан на информации из базы данных Scopus, ее аналитической надстройке SciVal, базе патентной информации Patstat и сервисах анализа вебометрических показателей Google и Ahrefs. Первый рейтинг вышел в 2009 г. и с тех пор публикуется ежегодно. Объектами ранжирования являются организации, выполняющие научные исследования и разработки, и университеты. Причем некоторые научные организации представлены в форме объединений: Российская академия наук, Китайская академия наук, Объединение им. Гельмгольца и т. д. Кроме того, в рейтинг входят и негосударственные компании — Google, Pfizer, IBM, Microsoft и т. д. Всего в SIR содержится пять категорий обследуемых учреждений, относящихся соответственно к государственному и частному секторам, сферам медицины (клиники, госпитали и пр.) и высшего образования, а также прочим областям.
2 SCImago Institutions Rankings. URL: http://www.scimagoir.com/methodology.php
Пороговый критерий для вхождения в рейтинг составляет минимум 100 научных работ, индексируемых в Scopus и опубликованных в течение года перед годом проведения оценки. Данные анализируются за пятилетний период за два года до проведения оценки, что связано в первую очередь с необходимостью введения лага для подсчета цитирований. Весь перечень показателей, используемых в рамках процедуры рейтингования, делится на три группы:
1)	исследования:
—	общее число публикаций (показатель имеет вес 8 % в интегральном рейтинге);
—	число публикаций, подготовленных совместно с иностранными коллегами (2 %);
—	средняя цитируемость публикаций, нормализованная по научным дисциплинам (13 %);
—	число публикаций, отнесенных к первому квартилю (2 %);
—	число публикаций в группе 10 % самых цитируемых работ в рамках научной дисциплины (2 %);
—	число публикаций, в которых сотрудник организации указан в качестве контактного лица (5 %);
—	число публикаций в группе 10 % самых цитируемых работ в рамках научной дисциплины, в которых сотрудник организации указан в качестве контактного лица (13 %);
—	число уникальных авторов публикаций (5 %);
2)	инновации:
—	число публикаций, процитированных в патентах (25 %);
—	доля публикаций, процитированных в патентах, в общем числе публикаций (5 %);
3)	социальный эффект:
—	число интернет-страниц, ассоциированных к сайту организации (5 %);
—	число входящих ссылок на домен организации (15 %).
Все показатели за исключением доли публикаций, процитированных в патентах, относятся к размеру организации с целью возможности сравнения различных по масштабу учреждений.
В 2017 г. анализу подверглось 5250 организаций (Россия была представлена 161 учреждением). Наиболее высокую позицию среди отечественных организаций заняла Российская академия наук — 25 место. Около трети российских представителей являются вузами, частный сектор не представлен вовсе. К государственному сектору были отнесены также институты РАН по отдельности и другие научно-исследовательские институты: Объединенный институт ядерных исследований, НИЦ «Курчатовский институт», НИИ онкологии им. Н. Н. Петрова и др.
Учет научных публикаций составляет основу и другого достаточно именитого рейтинга научных учреждений — Nature Index (NI)3. Но в отличие от SIR в NI информационную базу составляют 68 журналов преимущественно по естественным наукам, отбираемые независимыми экспертами. Рейтинг появился в 2012 г. и выходит ежегодно. Все оцениваемые организации, согласно методологии рейтинга,
3 Nature. A guide to the Nature Index. URL: https://www.nature.com/articles/d41586-017-07468-2
разделяются на два сектора: академический (в который помимо НИИ входят и университеты) и частный. В 2017 г. NI состоял из трех связанных рейтингов:
—	ранжирование организаций по абсолютному числу публикаций;
—	ранжирование организаций по числу публикаций, скорректированное по методологии фракционного счета (публикация делится на число авторов);
—	ранжирование организаций по числу публикаций, скорректированное по методологии фракционного счета и на понижающий коэффициент для журналов по астрофизике и астрономии.
Как и в SIR, лидером среди российских участников рейтинга стала РАН, которая по каждому из трех рейтингов вошла в ТОП-50. Всего в рейтинге 2017 г. более 100 российских вузов и научных институтов.
Помимо отмеченных трех рейтингов в рамках NI публикуются еще ряд отдельных региональных рейтингов (Япония, США, Саудовская Аравия, Китай и др.). Региональные рейтинги включают в себя дополнительные показатели, такие как число статей по естественным наукам, индексируемых в Scopus; число статей по естественным наукам, технологии, инженерии и математике, индексируемых в Web of science. Дополнительно публикуются небольшие (до 50—100 учреждений) рейтинги организаций, выполняющих исследования и разработки, по числу патентных семей и триадных патентов.
Принципиально иной подход ранжирования научно-исследовательских организаций применяется в European Research Ranking (ERR)4, объектом которого выступают проекты в области НИОКР, финансируемые Европейской комиссией. Впервые ERR был составлен для 2007 г. и ныне выходит ежегодно. По аналогии с другими рейтингами оцениваются не только научные организации, но и университеты (частных компаний почти нет). В рамках рейтинга публикуются позиции Т0П-100 организаций, которые за крайне редким исключением дислоцируются в Европе. Самобытность ERR заключается в наборе показателей, которые используются для ранжирования:
—	общий объем финансирования проектов, которые выполняла организация, определяемый методом фракционного счета;
—	общие число проектов, в реализации которых принимала участие организация;
—	репутация организация, измеряемая по методологии «пэйдж-ранк», т. е. чем больше проектов имеют партнеры организации, тем выше ее престиж.
Не менее интересными представляются индикаторы, которые были исключены из методологии рейтинга в процессе ее доработки:
—	соотношение новых и постоянных партнеров организации при реализации проектов;
—	отношение числа проектов, в которых организация являлась лидером, к количеству проектов, в которых организация была исполнителем;
—	индекс научной специализации (индекс Херфиндаля-Хиршмана по числу проектов в разрезе областей исследования).
Пороговым значением для включения в рейтинг его авторами установлено пять проектов. Неизменным лидером всех опубликованных рейтингов оставался
4 European Research Ranking. URL: http://www.researchranking.org/index.php?action=about
Национальный центр научных исследований во Франции, высокие места занимали Общество Фраунгофера и Общество Макса Планка.
Еще одним глобальным рейтингом учреждений, выполняющих НИОКР, является Top 25 Global Innovators — Government (GIG)5, составляемый компанией Рейтерс, по данным Web of Science, ее аналитического сервиса InCites и базе патентной информации Derwent. Этот рейтинг имеет два принципиальных отличия от рассмотренных ранее аналогов: во-первых, ранжируются исключительно государственные организации; во-вторых, оценивается вклад организаций преимущественно в генерацию технологий, а не знаний. GIG был впервые составлен в 2016 г. и также вышел в последующем году. Как утверждают создатели рейтингового продукта, в качестве исходной выборки были отобраны порядка 600 государственных научных организаций, сотрудники которых в период с 2009 по 2014 гг. опубликовали наибольшее число статей, индексируемых в Web of Science Core Collection. Далее отобранные учреждения были отсортированы по числу зарегистрированных патентов. В качестве порогового значения для составления рейтинга было установлено 70 патентов, которые отражаются в базе данных Всемирной организации по интеллектуальной собственности. Оставшиеся учреждения рейтингуются согласно следующим показателям:
—	количество зарегистрированных патентов (патентных семей);
—	доля успешных заявок на выдачу патентов;
—	количество триадных патентов;
—	количество цитирований патентов в других патентах;
—	количество цитирований патентов в других патентах в расчете на число выданных патентов;
—	доля процитированных патентов;
—	количество цитирований публикаций в патентах в расчете на число публикаций;
—	количество цитирований публикаций в публикациях, написанных представителями корпораций;
—	доля публикаций, написанных в соавторстве с представителями корпораций;
—	общее число публикаций.
По каждому из перечисленных показателей организациями присваиваются ранги. Все показатели имеют одинаковых вес за исключением количества цитирований патентов в других патентах и количества цитирований патентов в других патентах в расчете на число выданных патентов, к которым применяется поправочный коэффициент 0,5.
В итоговый рейтинг попадают только 25 лучших учреждений. В обоих опубликованных рейтингах GIG наибольшее представительство имели США, Франция, Япония и Германия (по 3—5 учреждений). Примечательно, что в число этих организаций попали учреждения, осуществляющие НОИКР в оборонной сфере: US NAVY и US ARMY. РАН занимала последнее место в 2016 г., а в следующем году выпала из рейтинга.
5 Methodology: Top 25 Global Innovators — Government. URL: https://www.reuters.com/ innovation/most-innovative-institutions-2017/methodology
Отдельно стоит выделить еще один рейтинг — Рейтинг мировых научных учреждений (WRIR)6, формируемый Европейской научно-промышленной палатой. WRIR выходит ежегодно с 2014 г. и подразделяется на 10 самостоятельных рейтингов по областям наук: биологические науки, технические науки, информатика, математические науки, медицинские науки, науки о Земле, общественные науки, сельскохозяйственные науки, физика и химия (названия слегка изменялись в зависимости от года публикации продукта). Однако достоверность и объективность данного рейтинга вызывает вопросы. Во-первых, на сайте WRIR не представлена методология рейтингования, указаны только категории, присваиваемые научным учреждениям — от D до AAA. Во-вторых, хотя рейтинг позиционируется как глобальный, ранжируются исключительно российские научные учреждения. В-третьих, в открытом доступе представлены крайне скудные сведения о Европейской научно-промышленной палате, что говорит о достаточно низком авторитете составителя рейтинга.
Отраслевые рейтинги научных организаций
Наряду с глобальными рейтингами составляются отраслевые рейтинги научных учреждений. Главным их преимуществом следует считать полную сопоставимость исследуемых объектов, т. е. исключение проблемы сравнения «физиков с лириками». Как было отмечено, отраслевые или предметные рейтинги формируются и в рамках глобальных рейтингов, что полностью соответствует логике наиболее известных и востребованных глобальных рейтингов университетов.В качестве наиболее яркого и разностороннего подобного предметного рейтингового продукта выступает семейство рейтингов портала Research Papers in Economics (RePEC)7, которые охватывают организации, выполняющие исследования в области экономических наук. RePEC был создан в 1997 г. и является «децентрализованной базой архивов научных материалов на разных языках мира, поддерживаемых издательствами и экономическими организациями из 87 стран на добровольных началах» [Шумилов, Балацкий, 2016]. На текущий момент в базе содержится более 2 млн научных публикаций, метаданные которых используются для построения различных рейтингов. Помимо рейтингов самих публикаций, журналов, авторов, стран, RePEC регулярно публикует широкий перечень рейтингов организаций. Выборка организаций формируется исходя из аффилиаций, которые указывают зарегистрированные авторы, а по типу организаций ограничения не устанавливаются. Так, например, кроме университетов и научных учреждений, в числе лидирующих учреждений встречаются Национальное бюро экономических исследований, Всемирный банк, Международный валютный фонд, Совет Федеральной резервной системы США и т. д.
Как уже отмечалось, на RePEC представлено семейство рейтингов, причем пользователь самостоятельно выбирает параметры для формирования каждого рейтинга. Основными показателями для формирования рейтингов являются:
—	число публикаций;
—	число публикаций, отнесенных к разряду выдающихся (рассчитывается по связке показателей цитируемости);
6	Рейтинг мировых научных учреждений. URL: http://www.eurochambres.org/wrir/
7	Research Papers in Economics. URL: https://ideas.repec.org/top/
—	число публикаций, отнесенных к разряду выдающихся, взвешенных на простой импакт-фактор;
—	число публикаций, отнесенных к разряду выдающихся, взвешенных на рекурсивный импакт-фактор (отличается от простого импакт-фактора учетом импакт-фактора изданий, являющиеся источником ссылок);
—	число публикаций, отнесенных к разряду выдающихся, взвешенных на количество авторов.
Всего предлагается более 30 библиометрических показателей для формирования рейтинга.
Также портал позволяет использовать 6 методов усреднения отобранных индикаторов, которые предварительно ранжируются:
—	среднее арифметическое частных рангов;
—	среднее гармоническое частных рангов;— среднее геометрическое частных рангов;
—	лексикографическое упорядочение (набор рангов по отдельным показателям для каждой организации сначала упорядочивается от лучшего к худшему. Затем полученные массивы рангов организаций в свою очередь упорядочиваются лексикографически, т. е. как слова в орфографических словарях — ранг 1 аналогичен первой букве алфавита. При таком способе агрегирования большое преимущество получают учреждения, имеющие выдающиеся результаты хотя бы по одному показателю) [Шумилов, Балац-кий, 2016];
—	графиколексическое упорядочение (на первом этапе сортируются индивидуальные ранги каждой организации, на втором — полученные массивы рангов организаций. Если на втором этапе используется лексикографический подход, то индивидуальные ранги каждой организации упорядочиваются от худшего к лучшему) [Шумилов, Балацкий, 2016];
—	сумма процентов от максимальных значений показателей.
также сервис позволяет добавлять фильтры по регионам, странам, областям экономической науки (более 50) и выделять типы организаций (например, центральные банки, международные организации, экономические департаменты/ отделы, финансовые департаменты/отделы, аналитические центры (think tanks) и т. д.). Если использовать базовые параметры портала (основной набор показателей и среднее арифметическое рангов), то по состоянию на апрель 2018 г. Институт экономической политики им. Е. Т. Гайдара занимает 24-е место в рейтинге аналитических центров, а НИУ ВШЭ располагается на 68 позиции в рейтинге экономических департаментов.
TOP Global contract research organizations (CRO)8 — диаметрально противоположный пример отраслевого рейтинга организаций, выполняющих НИОКР. Разработчиком рейтинга является портал IgeaHub, объединяющий менеджеров компаний, ученых, чиновников и т. д. в области здравоохранения и наук о жизни. Первый рейтинг CRO был составлен в 2016 г. и выходил в последующие два года. Как следует из названия рейтингового продукта, обследуются частные организации, выполняющие исследования и разработки в медицинской сфере. Публикуются результаты
8 TOP Global contract research organizations. URL: https://igeahub.com/2018/03/15/top-10-global-cros-2018/
только по 10 наиболее успешным предприятиям. В систему оценки входят следующие индикаторы:
—	годовая выручка (вес 70 % в интегральной оценке);
—	прирост выручки по отношению к предыдущему году (10 %);
—	чистая прибыль (5 %);— коэффициент затрат (5 %);
—	выручка в расчете на одного работника (5 %);
—	объем портфеля услуг (5 %).
По каждому из индикаторов организации присваивается ранг, затем ранги суммируются с учетом весовых коэффициентов. В трех опубликованных рейтингах доминировали организации из США, также в них присутствовали компании из Китая и Ирландии.
Еще одним представителем рейтингов организаций — в области здравоохранения — выступает Национальный рейтинг научных организаций и вузов Республики Казахстан9. Данный рейтинг составляется Республиканским центром развития здравоохранения и включает только казахские учреждения. Как указано на сайте разработчика продукта, «публикация ежегодного Национального рейтинга медицинских вузов и научных организаций предусмотрена Государственной программой "Денсаулык" на 2016—2019 годы и направлена на повышение прозрачности деятельности и конкурентоспособности казахстанских научных организаций в области здравоохранения». То есть, как и в случае с другими рейтингами, результаты ранжирования не применяются в качестве основного источника для принятия действий административного характера. Ежегодные Национальные рейтинги публиковались с 2013 г. Главное достоинство рейтинга — широкий перечень показателей — проистекает из способа получения исходной информации: организации присылают установленные формы с подтверждающими документами. Этот подход весьма схож с мониторингом деятельности научных организаций и вузов в России.
В методологии рейтинга обозначены баллы, которые присуждаются каждой единице достигнутого показателя. интегральная оценка происходит из суммирования баллов с учетом весовых коэффициентов, определенных для каждой группы показателей. Каждый из показателей рассчитывается на одну полную рабочую ставку. В дополнение к общему рейтингу публикуются субрейтинги вузов, клинических и неклинических НИИ и научных центров.
Всего выделяется 7 групп показателей:
1.	Выполненные научные исследования: научные проекты, выполненные в рамках бюджетного программно-целевого, грантового, внебюджетного финансирования, в т. ч. в коллаборации с зарубежными партнерами и представителями коммерческого сектора. Баллы присуждаются как за количество проектов, так и за объем полученного финансирования (вес группы показателей составляет 10 %);
2.	Количество публикаций в изданиях, индексируемых в библиометрических базах Web of Science, Scopus и Springer: принимается во внимание импакт-фактор журнала, в котором были опубликованы работы, и используется поправочный коэффициент по методологии фракционного счета (20 %);
9 Национальный рейтинг научных организаций и вузов Республики Казахстан. URL: http:// www.rcrz.kz/index.php/ru/glavnaya/22-informatsiya/214-rejting-nauchnykh-organizatsij-i-vuzov
3.	Количество цитирований публикаций за 5 лет: помимо Web of Science и Scopus подсчет цитирований ведется по Google Scholar и другим наукометрическим базам стран СНГ. Также баллы начисляются за индексы Хирша работников (20 %);
4.	Количество полученных охранных документов: учитываются документы, выданные национальным и зарубежными патентными офисами (15 %);
5.	Количество научных разработок: выделяются первичные (лекарственные препараты, биологические вещества и т. д.), вторичные (монографии и клинические руководства) и третичные (методические рекомендации, протоколы, статистические сборники и пр.) научные разработки (15 %);
6.	Коммерциализация результатов НИОКР: количество коммерциализированных результатов, объем средств от коммерциализации, а также новых медицинских технологий, полученных из-за границы и внедренных в организации (10 %);
7.	Участие в международных конференциях и форумах: количество выступлений и опубликованных тезисов докладов с индексацией в Web of Science или Scopus (10 %).
Всего в этих 7 группах присутствует 31 показатель. Это позволяет провести всестороннее обследование деятельности организаций. однако, как следует из распределения весовых коэффициентов, явное предпочтение отдается именно научной компоненте, а не внедрению технологий и получению инновационной продукции.
Вебометрические рейтинги научных организаций
Отдельную когорту рейтингов научных и научно-образовательных организаций составляют вебометрические рейтинги. В них во главу угла ставится успешность учреждений в популяризации научных знаний, представленность в интерактивном пространстве. В отличие от SIR, где вебометрика является лишь небольшой частью общей оценки, специализированные вебометрические рейтинги включают только показатели заметности в сети Интернет.
Одним из самых популярных таких рейтингов стал Ranking Web of World Research Centers (RWRC)10, созданный подразделением испанского государственного НИИ Cybermetrics Lab. Впервые RWRC был представлен общественности в 2008 г. и с тех обновляется два раза в год. Оценке подвергаются порядка 8000 учреждений, в число которых входят национальные академии и объединения организаций, исследовательские корпорации (например, Rand Corporation), лаборатории и центры университетов и пр. Интегральная рейтинговая оценка получается путем сложения помноженных на весовые коэффициенты рангов, полученных при ранжировании четырех показателей:
—	размер: количество страниц, индексируемых поисковыми сервисами Google, Yahoo, Live Search и Exalead;
—	видимость: количество уникальных внешних ссылок, полученных сайтом организации по данным сервисов Google, Yahoo, Live Search и Exalead;
10 Ranking Web of World Research Centers. URL: http://research.webometrics.info/en/world
—	полнотекстовые файлы (rich files): количество файлов форматов Adobe Acrobat (.pdf), Adobe PostScript (.ps), Microsoft Word (.doc) и Microsoft Powerpoint (.ppt);
—	востребованность в научной среде: количество публикаций и цитирований из библиометрической базы GoogleScholar.
Согласно рейтингу на январь 2017 г. в топ-10 вошли 6 американских научных учреждений, а также Общество Макса Планка, Национальный центр научных исследований Франции, Китайская академия наук и Высший совет по научным исследованиям Испании. Всего в RWRC представлено 856 российских организаций, выполняющих НИОКР. Наивысшую среди отечественных научных учреждений 30-ую позицию занимает РАН с высоким ранговым показателем полнотекстовых файлов. Следом идет Объединенный институт ядерных исследований (137 строчка в общем зачете) и Физический институт имени П. Н. Лебедева РАН (300-е место).
Очень схожий рейтинг был разработан и в России. Сотрудники Института вычислительных технологий в период с 2008 по 2014 г. регулярно составляли Рейтинг сайтов научных учреждений Сибирского отделения РАН11 [Шокин и др., 2008; 2012]. Данный рейтинг также содержит четыре показателя:
—	среднее арифметическое количества внешних ссылок на сайт по данным Яндекс, Google и Bing;
—	среднее арифметическое количества страниц на сайте по данным Яндекс, Google и Bing;
—	среднее арифметическое от количества PDF, DOC, PPT файлов по данным Яндекс и Google;
—	индексы цитирования, полученные из систем Индекс цитирования Яндекса и Google Scholar.
Как и в случае с RWRC, каждому показателю присваиваются ранги, которые затем суммируются для определения итоговой оценки.
Еще один вариант вебометрического рейтинга был подготовлен в Институте прикладных математических исследований Карельского научного центра РАН в 2013 и 2014 гг.12 Две итерации данного рейтинга, в отличие от предыдущего аналога, охватывали весь спектр научных организаций РАН за редким исключением. Кроме того, использовалась несколько измененная система показателей:
—	количество страниц сайта научного учреждения по данным Яндекс и Google;
—	количество внешних ссылок на сайт по данным Яндекс и Google;
—	количество PDF, DOC, PS файлов по данным Яндекс, Google и Google Scholar.
Непродолжительный период существования рейтинга, по всей видимости, связан с тем, что он создавался за счет средств гранта РГНФ и не получил дальнейшего финансирования. Еще одним эпизодическим вебометрическим рейтингом стало ранжирование научных организаций Россельхозакадемии [Сальников, 2012], которое имело очень близкую методологию с рассмотренными ранее аналогами.
11	Рейтинг сайтов научных учреждений Сибирского отделения РАН. URL: http://w.ict. nsc.ru/ranking/
12	Вебометрический рейтинг научных учреждений России. URL: http://webometrics-net. ru/section.php?id=33
Обзор зарубежных и российских рейтингов организаций, выполняющих исследования и разработки, показал, что для ранжирования используются в основном три группы показателей: библиометрические, финансовые и вебометрические. Способы получения интегральной оценки, так или иначе, сходятся к суммированию частных рангов с учетом весовых коэффициентов, определяемых экспертным путем. Хотя, конечно, существует значительно больше разновидностей рейтингов университетов, методологические подходы при составлении как тех, так и других рейтингов почти идентичны.
исследование мирового научного ландшафта при помощи SIR
Как уже отмечалось, рейтинги университетов весьма популярны. они активно используются в академической среде при изучении закономерностей развития высшего образования, поиске связей между ним и экономическими и институциональными условиями, наконец, выявлении причин стремительного восхождения или падения отдельных вузов. хотя рейтинги научных учреждений сравнимой популярностью не характеризуются, самый известный представитель — SIR — постепенно приобретает статус весьма заметного аналитического инструмента ученых-науковедов.
Так, Л. Борнманн совместно с коллегами создал портал excellencemapping.net с визуализацией данных SIR на карте мира [Bornmann и др., 2015], что наглядно проиллюстрировало распределение глобального научного потенциала. сервис позволяет оценить географическую концентрацию организаций по двум показателям: доля наиболее цитируемых публикаций в общем объеме опубликованных работ и доля публикаций в журналах первого квартиля. При расчете этих показателей возможно их взвешивание на числовые характеристики страны, к которой принадлежит оцениваемое учреждение: количество исследовательских организаций, ввП, численность граждан и даже национальный индекс восприятия коррупции. Кроме того, еще существует возможность взвешивания указанных показателей на долю публикаций организации, имеющих иностранных соавторов.
На примере SIR было продемонстрировано, что организации, имеющие четко выраженную дисциплинарную специализацию, занимают более высокие места в рейтинге по сравнению с центрами, проводящими исследования по широкому кругу научных направлений [Bornmann, de Moya Anegon, Mutz, 2013]. Организации медицинского профиля имеют особый успех, который достигается в основном благодаря высокой степени цитируемости работ наравне со средней скоростью получения этих цитирований. Этот вывод, помимо прочего, свидетельствует и в пользу необходимости специального дисциплинарного взвешивания интегральных показателей организаций при сравнении учреждений из разных научных направлений.
Объектом другой работы на основе данных SIR стал анализ публикационного профиля частных исследовательских компаний [de Moya-Anegon, Lopez-Illescas, Moed, 2014]. Было обнаружено, что на фоне университетов и государственных Нии коммерческим фирмам присущ более низкий валовой объем публикаций с более высоким средним уровнем цитируемости. Кроме того, авторы исследова-
ния оценили взаимосвязь между показателями результативности в SIR и объемом затрат на НИОКР — какой-либо статистически значимой зависимости выявить не удалось. Вполне очевидно, что основная цель деятельности фирм это получение прибыли, а не генерация потока публикаций. Наиболее явно это было подтверждено на таких традиционно прикладных областях, как автомобилестроение и телекоммуникации.
Поскольку в рамках SIR собираются данные по более чем десяти показателям деятельности научных учреждений, для ученых-наукометристов открываются широкие возможности в области разработки синтетических индексов. как раз такой индекс был предложен итальянскими учеными с учетом факторного анализа переменных [D'Uggento, Ricci, Toma, 2016]. Пожалуй, самым существенным выводом этой статьи можно признать обнаружение сильной положительной корреляции между несколькими показателями, что важно учитывать при составлении рейтингов.
результаты SIR с высокой долей вероятности и дальше будут служить удобным подспорьем для проведения наукометрических изысканий. Например, изучение характера влияния национальных или частных институциональных мер научной политики на количественные показатели результативности деятельности учреждений. Эти данные могут быть использованы и для регрессионного анализа с целью идентификации факторов успеха или провала повышения в рейтинге.
Эаключение
таким образом, рейтинги научных учреждений пока достаточно робко позиционируются на фоне других рейтинговых продуктов в научно-образовательной сфере. Но перспективы их большей востребованности и популярности четко вырисовываются и с точки зрения исследовательского интереса, и со стороны государственных регуляторов. Действительно, результаты рейтингов способны дать много новой информации для понимания факторов и проблем развития научных учреждений, в частности и для развития науки в целом. При том, что обширный аналитический аппарат уже накоплен и апробирован на рейтингах университетов, отдельных ученых или научных журналов.
Что касается интеграции рейтингов научных организаций в механизм принятия управленческих решений, то, судя по всему, по этому вопросу не может быть вынесено однозначно положительное решение. Научная ойкумена «в штыки» восприняла цель вхождения российских вузов в верхние сотни мировых рейтингов и с не меньшим скепсисом отнеслась к запуску ФСМНО. Вряд ли можно ожидать положительного отклика на постановку новой цели вроде вхождения отечественных научных учреждений в первую сотню SIR. Вместе с тем современная система управления научно-технологическим комплексом едва ли может обойтись без опоры на наукометрические данные. С одной стороны, это связывают с управленческим примитивизмом, а с другой — с размерами подобного комплекса, трудоемкостью и затратностью проведения повсеместной экспертизы. Поэтому рейтинги в том или ином виде могут и должны приносить пользу научным управленцам, а разработка и улучшение методологии ранжирования — как раз задача для научного сообщества.
Литература
Bornmann L. et al. Ranking and mappping of universities and research-focused institutions worldwide: The third release of excellencemapping. net // COLLNET Journal of Scientometrics and Information Management. 2015. Т. 9. № . 1. C. 65-72.
Bornmann L., de Moya Anegon F., Mutz R. Do universities or research institutions with a specific subject profile have an advantage or a disadvantage in institutional rankings? A latent class analysis with data from the SCImago ranking // Journal of the American Society for Information Science and Technology. 2013. Т. 64. № . 11. C. 2310-2316.
D'Uggento A.M., Ricci V., Toma E. A Proposal of An Indicator To Evaluate Research Activities Based On Scimago Institu-tions Ranking (SIR) Data: An Application To Italian High Education Institutions // Electronic Journal of Applied Statistical Analysis. 2016. Т. 9. № . 4. C. 655-674.
de Moya-Anegon F., Lopez-Illescas C., Moed H. F. How to interpret the position of private sector institutions in bibliometric rankings of research institutions // Scientometrics. 2014. Т. 98. № . 1. C. 283-298.
Балацкий Е. В., Екимова Н. А. Международные рейтинги университетов: практика составления и использования // Экономика образования. 2012. № . 2. C. 67-80.
Гуськов А. Е., Косяков Д. В., Селиванова И. В. Методика оценки результативности научных организаций // Вестник Российской академии наук. 2018. Т. 88. № 5. C. 430-443.
Николаенко Г. А., Федорова А. А. Российские университеты в мировых рейтингах: успехи, провалы, перспективы // Социология науки и технологий. 2017. Т. 8. № . 1. C. 96-112.
Сальников С. Г. Рейтинги сайтов научных организаций Россельхозакадемии // Никоновские чтения. 2012. № 17. С. 40-46.
Шокин Ю. И. и др. Рейтинг сайтов научных организаций СО РАН // Вычислительные технологии. 2008. Т. 13. № . 3. С. 128-135.
Шокин Ю. И. и др. Исследование научного веб-пространства Сибирского отделения Российской академии наук // Вычислительные технологии. 2012. Т. 17. № . 6. С. 85-98.
Шумилов А. В., Балацкий Е. В. Академические рейтинги RePEc: вопросы построения и роль российских участников // Журнал НЭА. 2016. № . 4. С. 111-138.
Rankings of Research Organizations
Maksim A. Yurevich
Junior Research Fellow, Financial University under the Government of the Russian Federation, Moscow, Russia e-mail: [email protected]
Abstract: Rankings of universities, scientific journals or scientists are very popular among the scientific and educational community and S&T administrators. Ratings of scientific organizations have not yet become so common, but there are more and more attempts to create them year by year in different countries. This article describes three main subclasses of such ratings: global, subject and webomet-ric ratings of scientific organizations. In General, the set of variables used and the methods of their processing or averaging are almost identical to the university rankings. The indicators of publication and patent activity, financial performance, as well as representation in an interactive environment are mainly used. As follows from the review, the developers of ratings often do not seek to form a final ranking of R&D organizations and suggest the user of the resource to choose the sorting configuration and get a personal rating. This feature opens up opportunities for scientists to analyze the activities of scientific institutions, identify the prerequisites and problems of organizations' promotion in the created ratings. The final part of the work describes the research of the global scientific landscape with the
help of the most famous of all the rankings of scientific institutions — Scimago Institutions Rankings. Successful attempts to identify the specific characteristics of private research companies, highly specialized scientific institutions through the prism of the rating confirm their high analytical potential. In addition, the developed methodological approaches of foreign and Russian ratings can be extremely useful for the improvement of scientific institutions' evaluation and monitoring system. Keywords: rankings, research organizations, scientometrics, webometrics, science policy.
References
Bornmann L. et al. (2015), "Ranking and mappping of universities and research-focused institutions worldwide: The third release of excellencemapping. net" in COLLNET Journal of Scientometrics and Information Management, 1 (9), pp. 65—72.
Bornmann L., de Moya Anegon F., Mutz R. (2013), "Do universities or research institutions with a specific subject profile have an advantage or a disadvantage in institutional rankings? A latent class analysis with data from the SCImago ranking" in Journal of the American Society for Information Science and Technology, 11 (64), pp. 2310—2316.
D'Uggento A. M., Ricci V., Toma E. (2016), "A proposal of an indicator to evaluate research activities based on Scimago Institutions Ranking (SIR) data: an application to Italian high education institutions" in Electronic Journal of Applied Statistical Analysis, 4 (9), pp. 655—674.
de Moya-Anegon F., Lopez-Illescas C., Moed H. F. (2014), "How to interpret the position of private sector institutions in bibliometric rankings of research institutions" in Scientometrics, 1 (98), pp. 283-298.
Balackij, E.V. and Ekimova, N.A. (2012), "Mezhdunarodnye rejtingi universitetov: praktika sos-tavlenija i ispol'zovanija" ["International university rankings: practice of creation and application"] in Jekonomika obrazovanija [Educationaleconomics], 2, pp. 67-80 (in Russian).
Gus'kov, A.E., Kosjakov, D.V., Selivanova, I.V. (2018), "Metodika ocenki rezul'tativnosti nauch-nyh organizacij" ["Methods of evaluation of scientific organizations"] in Vestnik Rossijskoj akademii nauk [Herald of the Russian Academy of Sciences], 5 (88), pp. 430-443 (in Russian).
Nikolaenko, G.A. and Fedorova, A.A. (2017), "Rossijskie universitety v mirovyh rejtingah: uspe-hi, provaly, perspektivy" ["Russian universities in the world rankings: successes, failures, prospects"] in Sociologija nauki i tehnologij[Sociology of science & technology], 1 (8), pp. 96-112 (in Russian).
Sal'nikov, S.G. (2012), "Rejtingi sajtov nauchnyh organizacij Rossel'hozakademii" ["Ratings of sites of the scientific organizations of Russian Academy of agricultural Sciences"] in Nikonovskie chtenija [Nikon reading], 17, pp. 40-46 (in Russian).
Shokin Ju.I. et al. (2008), "Rejting sajtov nauchnyh organizacij SO RAN" ["Rating of sites of scientific organizations SB RAS"] in Vychislitel'nye tehnologii [Computational technologies], 3 (13), pp. 128-135 (in Russian).
Shokin Ju.I. et al. (2012), "Issledovanie nauchnogo veb-prostranstva Sibirskogo otdelenija Rossijskoj akademii nauk" ["Research of the scientific web space of the Siberian branch of the Russian Academy of Sciences"] in Vychislitel'nye tehnologii [Computational technologies], 6 (17), pp. 85-98 (in Russian).
Shumilov, A.V. and Balackij, E.V. (2016), "Akademicheskie rejtingi RePEc: voprosy postroenija i rol' rossijskih uchastnikov" ["Academic rankings RePEc: questions of construction and the role of Russian parties"] in ZhurnalNJeA[Journalof the New economic association], 4, pp. 111-138 (in Russian).
