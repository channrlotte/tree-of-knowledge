УДК 004.912
12	12	12	13
Е. А. Сидорова ' , С. В. Анохин ' , И. С. Кононенко ' , Н. В. Саломатина '
1 Новосибирский государственный университет ул. Пирогова, 2, Новосибирск, 630090, Россия
2 Институт систем информатики им. А. П. Ершова СО РАН пр. Акад. Лаврентьева, 6, Новосибирск, 630090, Россия
3 Институт математики им. С. Л. Соболева СО РАН пр. Акад. Коптюга, 4, Новосибирск, 630090, Россия
[email protected]; [email protected], irina_k@cn.т; [email protected]
ТЕМАТИЧЕСКИЙ АНАЛИЗ ЗАПРОСОВ ПОЛЬЗОВАТЕЛЕЙ НА ОСНОВЕ ПРЕДМЕТНО-ОРИЕНТИРОВАННОГО СЛОВАРЯ *
Предложен подход к тематической классификации коротких текстов, основанный на применении тематических словарей предметной лексики. Рассматривается технология разработки тематических словарей и методы автоматизации их обучения в ситуации отсутствия обучающей выборки целевых текстов достаточного объема. Приводится описание алгоритма тематической классификации и результаты его экспериментального исследования на коллекции пользовательских интернет-запросов, для которых требовалось определить тематику в соответствии с рубрикатором видов деятельности в Интернете.
Ключевые слова: анализ запросов, тематический анализ, классификация коротких текстов, предметный словарь, обучение словаря, оценка релевантности.
Введение
Обработка естественного языка представляет собой динамично развивающуюся область исследований с широким спектром практических приложений. Одним из перспективных ее направлений является построение естественно-языковых интерфейсов в интернет-среде. Естественный язык - наиболее доступная для человека форма выражения потребностей, что делает человеко-машинное взаимодействие на его основе весьма привлекательной альтернативой созданию сложных графических интерфейсов и применению искусственных проблемно-ориентированных языков, малопригодных для привлечения широкой аудитории. К сожалению, существенным препятствием к практическому применению естественно-языковых интерфейсов остается значительная сложность реализации в сочетании с высокой себестоимостью.
Одним из методов обработки текстовой информации на естественном языке, широко применяемых в настоящий момент, является классификация текстов в соответствии с заданным тематическим рубрикатором. Пользовательский запрос, как одна из разновидностей корот-
* Работа выполнена в Новосибирском государственном университете при финансовой поддержке Министерства образования и науки Российской Федерации (договор № 02.G25.31.0054).
Сидорова Е. А., Анохин С. В., Кононенко И. С., Саломатина Н. В. Тематический анализ запросов пользователей на основе предметно-ориентированного словаря // Вестн. Новосиб. гос. ун-та. Серия: Информационные технологии. 2014. Т. 12, вып. 4. С. 83-95.
ISSN 1818-7900. Вестник НГУ. Серия: Информационные технологии. 2014. Том 12, выпуск 4 © Е. А. Сидорова, С. В. Анохин, И. С. Кононенко, Н. В. Саломатина, 2014
ких текстов, также нуждается в классификации для выявления области интересов пользователя. Методы тематической классификации запросов активно исследуются разработчиками информационно-поисковых систем в целях обеспечения более релевантного отклика [1]. Кроме этого классификация запросов применяется для извлечения различной метаинформа-ции (язык и кодировка запроса, пол автора [2], его эмоциональное состояние [3] и т. п.), которая затем может быть использована для более точного тематического анализа или демонстрации пользователю контекстной рекламы.
Классификации текстов на естественном языке посвящено большое количество публикаций как отечественных, так и зарубежных авторов (см., например, [4] 1). Однако задача обработки пользовательских запросов обладает рядом особенностей, затрудняющих применение методов, ориентированных на обработку полнотекстовых документов. Некоторые из этих особенностей перечислены ниже.
1.	Пользовательские запросы, как правило, представляют собой сверхкороткие тексты. Так, согласно исследованию 2, средний размер запросов к поисковой системе Яндекс составляет около 5 слов и демонстрирует тенденцию к незначительному росту. При этом доля запросов, содержащих более 10 слов, не превосходит 15 %.
2.	В запросах содержится меньше «шумовой» лексики, чем в полнотекстовых документах. Как отмечается в [5], краткость таких текстов, как заголовки и поисковые запросы, практически исключает случайное попадание в них тематически-окрашенных слов и словосочетаний. В эксперименте, описанном в работе [6], удалось увеличить точку безубыточности для микроусредненных полноты и точности классификатора с 0,789 до 0,805 путем удвоения веса терминов, встретившихся в заголовке документа. Аналогичные результаты были получены в [7] для задачи классификации HTML-документов, решавшейся в рамках структурно-ориентированного подхода, предполагающего назначение терминам различных весов в зависимости от элемента, в котором они встретились. В результате присвоение наибольших весов терминам, встретившимся в элементах META и TITLE, позволило улучшить аккуратность классификатора. Можно ожидать, что значительная тематическая окрашенность терминов является общим свойством текстов, предназначенных для передачи информации в сжатой форме, причем пользовательские запросы относятся именно к этой категории текстов.
3.	Запросы могут формулироваться на разных языках, поэтому желательно применять один и тот же подход независимо от того, на каком именно языке формулируется конкретный запрос. В достаточно распространенном случае, когда в качестве классифицирующих признаков используется присутствие или отсутствие отдельных терминов, такая постановка задачи приводит к необходимости учитывать морфологию целевого языка.
4.	В некоторых случаях представительный корпус запросов достаточного объема может отсутствовать, тогда как его создание представляется весьма трудоемкой задачей. В связи с этим мы сознательно стремимся ослабить потребность в подобного рода корпусах при построении классификатора.
5.	Классификация может осуществляться относительно большого числа рубрик. Как отмечается в работе [8], для извлечения наиболее точной информации методами классификации разработчики рубрикаторов стремятся учесть как можно больше конкретных направлений, что приводит к появлению рубрикаторов, насчитывающих сотни и тысячи рубрик. В результате на каждую рубрику приходится не более 1 % обучающей выборки, что предъявляет слишком обременительные требования к ее объему. В свете предыдущего пункта использование методов машинного обучения может оказаться проблематичным для решения рассматриваемой здесь задачи.
Перечисленные особенности делают применение отдельных методов классификации слабоосуществимым. Например, подход, предлагаемый в работе [9], показывает очень хорошие результаты на полнотекстовых документах, однако имеет две существенных особенности, не
1	См. также: Агеев М. С. Методы автоматической рубрикации текстов, основанные на машинном обучении и знаниях экспертов: Дис. ... канд. физ.-мат. наук. М., 2004. URL: http://www.cir.ru/docs/ips/publications/2005_diss_ ageev.pdf.
2	Яндекс «Поиск в интернете: что и как ищут пользователи» // Информационный бюллетень компании Яндекс, 2009. URL: http://download.yandex.ru/company/yandex_search_mini_report_autumn_2009.pdf (дата обращения 30.10. 2014).
позволяющих применять его для решения нашей задачи. Во-первых, ресурс, аналогичный тезаурусу РуТез, не всегда доступен для заданных категорий и целевого языка. Во-вторых, небольшая длина запросов делает бессмысленным применение анализа на основе построения тематических узлов текста, предлагаемых авторами в качестве элемента тематической модели.
В работе [9] рассматриваются особенности применения методов машинного обучения для определения авторства коротких сообщений, оставляемых на форумах и в социальных сетях. В работе [2] те же исследователи решали задачу определения пола автора короткого сообщения. Точность классификации, полученная для различных методов обучения и характеристик текстов, составила порядка 0,6-0,7. Однако, как отмечалось выше, для успешного применения методов машинного обучения в рамках нашей задачи требуется создание объемного корпуса запросов, что весьма затруднительно. Кроме того, каждый текст можно рассматривать как сообщение в рамках определенного жанра. Подобные тексты имеют несколько иные цели, по сравнению с запросами, так, отличие сообщений форумов заключается, в частности, в их особой эмоциональной окрашенности и употреблении разнообразных языковых средств выражения эмоций.
Решению достаточно близкой задачи посвящена статья [5], в которой рассматривается метод тематической рубрикации сверхкоротких текстов, основанный на экспертных знаниях, а также анализируются некоторые сложности, сопряженные с данной задачей. Полнота и точность, полученные в результате тестирования метода на коллекции поисковых запросов, составили 0,66 и 0,98 соответственно. К сожалению, авторы не предлагают методики, которая бы позволила упростить формирование тематических словарей.
Цель данного исследования - разработать подход и методы тематической классификации, адаптированные для анализа коротких пользовательских запросов к автоматизированным сервисам. При этом существенным условием является то, что для успешного применения предлагаемых методов не требуется наличие исходного обучающего корпуса целевых запросов, что значительно повышает роль эксперта при создании качественных рубрикаторов и предполагает разработку автоматизированных средств, облегчающих настройку используемых словарей.
Предметно-ориентированный словарь
Предметный словарь необходим для решения различных задач и используется для: а) согласованного общения «на одном языке» экспертов и разработчиков информационных систем; б) исследования характеристик объектов и процессов, составляющих рассматриваемую ПО; в) выявления основных логических взаимосвязей между понятиями, которые соответствуют введенным терминам; г) как необходимый инструмент обработки текстов на ЕЯ.
В рамках нашего подхода словарь - это необходимый инструмент, в котором хранится вся необходимая информация для выделения терминов из текста запроса и его тематического анализа [10].
Предметно-ориентированный словарь - это объем лексики, организованной по тематическому (семантическому) принципу с отражением определенного набора базовых семантических отношений определенной предметной области. Наличие групп, объединяющих в себе множество синонимических выражений одного понятия, позволяют словарю выполнять функции тезауруса.
Модель знаний о лексике предметной области должна включать спецификации терминов трех типов:
1)	лексема или однословный термин, который включает информацию обо всей совокупности форм, описываемых парами <основа, парадигма>;
2)	устойчивый словокомплекс - словосочетание, характеризующееся наличием определенной синтаксической связи между контактно расположенными словами и высокой частотностью в анализируемом подъязыке;
3)	устойчивая Л-грамма - цепочка из N подряд следующих слов, встречающаяся в рассматриваемом подъязыке с высокой частотностью и обладающая свойством законченности, т. е. невозможностью расширения левого и правого контекстов без потери частоты.
Автоматизировать различные процессы разработки лингвистических ресурсов позволяет статистическая информация, накапливаемая в словаре. Для каждого термина словаря необходимо предоставлять следующую информацию: встречаемость в обучающей выборке, текстовую частоту, а также встречаемость и тестовую частоту отдельно по каждой тематике (если такая разметка задана).
Формально словарь определяется знаковой системой вида:
V = < Ь, М, Б, Rs, Ж >, где
Ь = Ж и Р и N - множество предметных терминов, включающих Ж - множество лексем, Р - множество словокомплексов, N - множество ^грамм;
М - морфологическая модель языка, представленная множеством морфологических классов и характеристик лексем Ж;
5 - множество тематических признаков с заданными иерархическими связями;
Rs - множество контекстных синонимических отношений между терминами Ь, посредством которых формируются группы терминов, связанных отношением синонимии, с выделенным главным термином и указанным контекстным тематическим признаком 5;
- множество связей между терминами и признаками, где каждая связь наделяется количественными характеристиками, отражающими частоту появления термина в текстах в указанной признаком роли (в частности, частоту термина в текстах определенной тематики).
Таким образом, основными особенностями рассматриваемого словаря являются:
•	наличие многословных терминов, представленных либо устойчивыми словосочетаниями, либо ^граммами;
•	учет контекста в отношениях синонимии, что позволяет более эффективно указывать особенности использовании терминологии в предметных областях и их подобластях;
•	иерархичная организация тематических / семантических признаков с поддержкой множественного наследования;
•	накопление частотных характеристик для терминов и признаков словаря.
Лексикон представляет собой подсловарь однословных терминов, который формируется на основе универсального морфологического словаря. Для русского и английского языков это морфологические словари группы Диалинг [11]. Единица лексикона - лексема, т. е. слово во всей совокупности его форм и значений.
Словарная статья лексемы содержит следующую лексемообразующую информацию:
•	нормальная форма слова;
•	основа - неизменяемая часть лексемы (у некоторых лексем основа может быть пустой, тогда лексема определяется парадигмой);
•	парадигма - набор псевдофлексий или изменяемых частей слова, к которым в отдельных случаях относятся и префиксы (приставки);
•	морфологический класс (класс, в частности, включает часть речи и постоянные для всех словоформ данной лексемы морфологические признаки);
•	тип термина - слово универсального словаря, предсказание, слово служебного словаря и т. п.
Уникальной отличительной чертой предлагаемой технологии формирования лексикона является то, что набор морфологических классов может настраиваться пользователем-лингвистом. В зависимости от предметной области и решаемой задачи разработчикам может потребоваться сузить (объединить) или расширить набор классов, например, добавить классы имен / отчеств / фамилий для распознавания персон, если это необходимо. Также эта функция полезна при поддержке мультиязычности и настройке на новые языки.
Для поддержки функциональности морфологической настройки предложены и реализованы следующие механизмы.
1. Редактируемая система морфологических атрибутов и классов. С этой целью поддерживается загрузка текстового описания типов, заданного по определенной форме.
X = {хь..., хп} // Число={ед, мн} - описывает атрибут и список возможных значений.
¡ёРБ {Х^Ху, ., Хьх^ } // t Сущ {Одушевленностъ.од, ИмяСобственное:фам} - задает описание морфологического класса, для которого заданы неизменяемые морфологические атрибуты.
id1 ...idn = (Хъ ...,Xk} // bcgim={Число,Падеж} - описывает класс парадигмы, для которого указываются морфологические классы с данным типом словоизменения и набор изменяемых морфологических атрибутов.
2.	Правила преобразования морфологической системы подключаемого универсального словаря во «внутреннюю» систему. Правила задаются текстовым описанием следующего вида:
X = Y1;...; Yn // Г=Глаг;Инф;Деепр - описывает правило сопоставления морфологических атрибутов;
<rule_class: P> - строка открывает группу правил определения морфологического класса для заданной части речи P «внешней» системы. Далее в порядке приоритета заданы наборы атрибутов и сопоставляемый им «внутренний» класс:
x1 +...+ xn= Y// жр+од=с - упорядоченность такого рода правил означает, что если термин удовлетворил одному правилу, то остальные не применяются (таким образом обеспечивается однозначность).
3.	Автоматическое построение таблиц парадигм с использованием универсального механизма хеширования набора морфологических атрибутов.
Парадигма представляет собой набор псевдофлексий, где каждой псевдофлексии сопоставляется набор индексов, вычисляемых по набору морфологических атрибутов словоформы с данной флексией в соответствии с типом парадигмы. Подробное описание алгоритмов хеширования, а также лемматизации и поиска морфологических характеристик слов выходит за рамки темы данной статьи.
На основе морфологических характеристик слов осуществляется поиск словосочетаний в соответствии с синтаксической моделью языка.
Устойчивые словосочетания. Синтаксическая модель языка описывается экспертом для заданного подъязыка и морфологической модели в терминах лексико-синтаксических шаблонов и их обобщений. При разработке шаблонов формируется иерархическое представление синтаксической структуры словосочетаний, где связь между элементами словосочетания осуществляется на основе морфологических атрибутов.
Формально шаблон - это четверка вида
< Name, P, root, R, RN >, где
Name - название или имя шаблона;
P - последовательность элементов, в которой каждый элемент сопоставляется одному или нескольким терминам в тексте;
root - корневой элемент в шаблоне;
R - правила согласования элементов шаблона, выраженные в терминах морфологических атрибутов и устанавливающие либо согласование какого-либо элемента с корневым (в этом случае указывается набор морфологических атрибутов, которые должны согласовываться), либо управление (в этом случае для элемента указываются значения морфологических атрибутов);
RN - правила синтеза имени словосочетания, в случае когда это необходимо (данный набор может быть пустым).
Вводится иерархия обобщенных шаблонов, в которой шаблоны с разной степенью обобщения описывают свои составляющие.
1.	Атомарный шаблон, описывающий точное словосочетание. Элементами P атомарного шаблона могут являться либо точные словарные лексемы, либо их словоформы. Например: [солнечный] + [день] (род, число, падеж). Для атомарного шаблона необходимо также указать правила синтеза нормализованного имени (в простейшем случае имя формируется из нормальных форм составляющих).
2.	Абстрактный шаблон, связывающий группы слов, объединенных общностью морфологических признаков. Элементы P описываются морфологическими классами и атрибутами. Например: ИГ = [Прил] + [Сущ] (род, число, падеж).
3.	Обобщенный шаблон, в состав которого могут входить другие шаблоны. Элементами P могут являться другие шаблоны, в том числе и данный шаблон. Например, [Сущ] + ИГ(падеж=рд, число=ед).
На основе абстрактных и обобщенных шаблонов можно осуществлять поиск словосочетаний в обучающей выборке и строить по ним атомарные шаблоны, которые будут входить в состав терминологического словаря в качестве кандидатов в термины-словокомплексы.
Термин-словокомплекс - устойчивое терминологическое сочетание, характерное для данного подъязыка (тематики, жанра, стиля, коллекции текстов, ср. [12]). На первом этапе извлекаются все возможные словосочетания и строятся гипотезы, на следующих этапах отбираются устойчивые в данном подъязыке гипотезы и фиксируются в словаре, остальные гипотезы удаляются.
Словарная статья словокомплекса содержит следующие признаки:
•	нормальная форма словокомплекса (имя атомарного шаблона);
•	список составляющих однословных терминов;
•	идентификатор правила, согласно которому образовался данный термин.
В процессе классификации поиск словокомплексов осуществляется в первую очередь на основе его лексического состава, для которого далее производится проверка согласования, заданного правилом.
В случае отсутствия правил для первоначальной сборки словокомплексов применяется ^граммный анализ текста, в котором в качестве многословных терминов выступают ^граммы.
Nграммы. Под Nграммой (хы) понимается цепочка из N подряд следующих слов текста. Совокупность ^грамм, описывающих текст Т, формируется путем анализа содержимого окна ширины N, скользящего вдоль текста со сдвигом на одно слово.
Привлекательными сторонами ^граммного подхода являются: применимость к разноязычным текстам (язык, на котором написан текст, может учитываться только на этапе предобработки, например, лемматизации), ориентация на извлечение терминов произвольной длины, оценка их информативности путем привлечения позиционной информации, возможность формирования шаблонов для описания групп близких ^грамм и установления связей между ними.
Таким образом, текст представляется совокупностью всевозможных найденных в нем ^грамм с указанием их частот встречаемости Fa(xN) и, при необходимости, их позиций в тексте. Для нормализованных текстов, в которых все слова приведены к канонической форме, для всех слов, составляющих ^грамму, указываются также грамматические характеристики. Сравнение ^грамм при формировании словаря осуществляется только по их словарному составу без учета других характеристик. Параметр N обычно пробегает значения от 1 до N„^(1), где N„^1) - длина максимальной повторяющейся более одного раза цепочки слов в тексте.
Словарная статья ^граммы содержит следующие признаки:
•	нормальная форма ^граммы (перечень имен составляющих);
•	список составляющих однословных терминов;
•	частотная характеристика.
Для анализа устойчивости ^грамм рассматривается обучающая выборка текстов К = (Т\, Т2,..., Т„), для которой вычисляются совместные ^граммные характеристики, содержащие всевозможные N граммы, общие хотя бы для пары текстов. Каждая ^грамма сопровождается информацией не только о частоте Fa(xN) встречаемости в текстах подборки К (абсолютной), но и о текстовой FT(xN), равной числу текстов из К, в которых она представлена. Параметр N меняется от 1 до ^^(К), где Nmcx(K) - длина максимального межтекстового повтора. Наиболее перспективными, в плане принадлежности к терминологической лексике, являются ^граммы с неравномерным распределением по текстам из К.
Модель представления текста. В процессе обработки текста его представление постепенно изменяется, становясь более структурированным. Для описания этого изменения предложена концепция покрытий текста, когда каждое покрытие представляется набором однотипных элементов с заданными текстовыми позициями (интервалами). Выделяются следующие типы покрытий:
1) графематическое - представляет собой разбиение текста на элементарные составляющие, такие как слово, знак препинания, абзац, число, и содержащее пометы вида заголовок, выделение, элемент списка и т. п.;
2)	терминологическое покрытие состоит из словарных терминов, найденных в данном тексте с учетом возможной омонимии и пересечения многословных терминов;
3)	тематическое покрытие - это терминологическое покрытие с указанием тематики для каждого элемента покрытия.
Для каждого термина, найденного в тексте, формируется лексический объект O и снабжается словарной и текстовой информацией:
O = <v, Mv, Sv, Av, pos>, где
v<eL - термин словаря;
Mv - множество морфологических характеристик термина;
Sv - множество тематических признаков термина v;
Av - графематическая составляющая термина v;
pos - интервал позиций в тексте, покрываемых найденным терминов (его графематиче-ской составляющей).
В процессе построения тематического покрытия решаются задачи разрешения омонимии, исключения терминов, входящих в состав других терминов, выявления главных синонимов и формирования множества гипотез о тематике(-ах) текста на основе наличия связей <термин, тематика> в словаре.
Таким образом, алгоритм тематической классификации текста получает на вход модель текста в виде тематического покрытия и осуществляет вычисление релевантных тематик на основе данных, содержащихся в лексических объектах покрытия и всей связанной словарной информации.
Тематический анализ запросов
Описав структуру и основные характеристики тематических словарей, перейдем к рассмотрению процедуры классификации пользовательских запросов. В рамках нашего подхода классификация осуществляется на основе предметной лексики и статистических данных, представленных в этих словарях.
Постановка задачи. Итак, мы предполагаем, что имеется некоторый фиксированный рубрикатор J, в котором может содержаться от сотен до нескольких тысяч рубрик, соответствующих темам запросов. Дополнительно на множестве рубрик из J может быть определено транзитивное-антисимметричное отношение наследования <, отражающее связь «общее -частное» между отдельными рубриками. Элементы J будем обозначать символами ть т2, ... и т. д. В контексте решаемой нами задачи рубрикатор, как правило, будет иметь ограниченную предметную область. Под этим подразумевается, что принципы, исходя из которых выделяются индивидуальные рубрики и, соответственно, задается структура рубрикатора, в первую очередь определяются соображениями прагматического характера.
Возможные запросы представляют собой микротексты - короткие или сверхкороткие фразы (в среднем 3-4 слова), написанные на специфическом фрагменте естественного языка, аналогичного языку запросов к поисковой системе, синтаксис которого сводится к номинативным (чаще) или глагольным (реже) конструкциям, нередко выстраивающимся в уточняющие последовательности. После обработки словарной системой запрос задается в виде терминологического покрытия. Множество всех возможных покрытий (запросов) обозначим как Q, а индивидуальные покрытия - символами ю1, ю2, ... и т. д. Как отмечалось, произвольное покрытие ю задается в виде множества лексических объектов (экземпляров словарных терминов произвольного типа), для каждого из которых среди прочего известны тематические признаки и позиция в тексте запроса. В качестве тематических признаков могут выступать некоторые статистические меры, вычисленные по корпусу полнотекстовых документов, однако мы для простоты будем считать, что тематические признаки заданы путем простого перечисления потенциально релевантных тем.
Формально мы должны построить алгоритм, вычисляющий функцию f: ^ [0, 1], которая для каждой темы и для каждого запроса определяет степень их соответствия - релевантность. Таким образом, мы предполагаем, что запросу может соответствовать более одной темы, а само соответствие может иметь произвольный вес от 0 до 1, где 0 означает, что тема никак не связана с запросом, а 1 означает, что тема полностью релевантна.
Описание алгоритма анализа запроса. Алгоритм анализа запроса пользователя основан на четырех базовых процедурах: Lemmatize, ParseText, ThemeCover и CalcRelevance. Рассмотрим их по отдельности.
1.	Процедура Lemmatize осуществляет поиск лексемы из множества W словарных лексем по любой ее форме (упрощенный морфологический анализ или лемматизация). Данный поиск работает в двух режимах: 1) поиск по префиксу словоформы и 2) поиск по полной словоформе. Более формально, процедура имеет следующую сигнатуру.
Процедура: Lemmatize(word, mode).
Вход: word - строка (слово или часть слова), mode - маркер режима.
Выход: множество {l1, ..., ln} с W однословных терминов словаря, для которых строка word является допустимым написанием (или его частью).
Например, результатом выполнения Lemmatize(«автомо», режим_1) будет множество словарных лексем {автомобиль, автомобильный, автомойка, автомоечный}. Конкретный алгоритм лемматизации в общем случае может зависеть от языка, на котором сформулирован пользовательский запрос. Поскольку множество возможных интерпретаций каждого слова заведомо ограничено множеством W, разумно воспользоваться этой информацией при реализации процедуры Lemmatize. Например, для большинства флективных и аналитических языков морфологический анализ можно осуществлять на основе префиксного дерева, содержащего все возможные словоформы лексем из W.
2.	Базовая процедура ParseText осуществляет поиск многословных терминов.
Процедура: ParseText(lexemes).
Вход: lexemes - последовательность лексем, сгруппированных с учетом омонимии <L1,L2,. ,Ln>, где каждое множество Li с W содержит возможные интерпретации i-го слова пользовательского запроса.
Выход: множество найденных словокомплексов словаря (с сохранением позиций).
Например, для запроса вида «сайт сервиса мойки автомо»: входом данного алгоритма будет последовательность <{сайт}, {сервис}, {мойка}, {автомобиль, автомобильный, автомойка, автомоечный}>, результатом - словокомплекс {мойка автомобиля}.
3.	Построение тематического покрытия текста. Данный алгоритм формирует окончательную модель текста и подготавливает необходимые данные для завершающего этапа - классификации.
Процедура: ThemeCover(rn).
Вход: ш ей - терминологическое покрытие текста, представленное в виде упорядоченного множества терминов словаря (со всей информацией, которая приписана данным терминам в словаре, а также позициями в тексте запроса).
Выход: тематическое покрытие Y с ю х X - отношение, связывающее отдельные темы из X с лексическими объектами из ю.
На данном этапе последовательно решаются следующие задачи.
•	Вычисление количества омонимов для каждого термина терминологического покрытия. Задача решается на основании позиций, приписанных элементам покрытия.
•	Разрешение омонимии. Задача решается на основании словарной информации о составе многословных терминов в случае, если один из омонимичных терминов входит в состав словокомплекса.
•	Исключение терминов, входящих в состав других терминов. Данная задача решается на основании информации о позициях терминов.
•	Поиск синонимов и замена терминов терминологического покрытия на их дескрипторы (т. е. главный термин группы синонимов). Задача решается на основании словарной информации о синонимических группах с учетом тематического контекста.
•	Формирование множества гипотез о тематике(-ах) текста на основе наличия связей <термин, тематика> в словаре с учетом тематического контекста дескрипторов.
4.	Тематическая классификация осуществляется процедурой CalcRelevance, вычисляющей релевантности тематик, входящих в тематическое покрытие текста, и выбором наиболее подходящих тематик на основании полученных оценок. При вычислении релевантности необходимо учитывать различные количественные характеристики, такие как степень неоднознач-
ности терминов, количество различных тем, приписанных терминам, «универсальность» слов и т. п.
Процедура: CalcRelevance(Y).
Вход: Y - тематическое покрытие запроса.
Выход: множество {<ть r1>, .. .,<тп, rn>} тематик ^е'Х с приписанными им весами r;e [0, 1].
Таким образом, ключевой функцией алгоритма анализа запросов пользователей является функция вычисления релевантности всех тематик, вошедших в список тематик-кандидатов в процессе построения тематического покрытия текста.
Вычисление релевантности тематик осуществляется на множестве тематик с полученным в результате построения тематического покрытия запроса Y. Все термины упорядочены по своей позиции в тексте запроса и могут быть сопоставлены нескольким тематикам.
Введем следующие обозначения:
l, ю - однословный термин запроса;
Pj ею - словокомплекс, найденный в запросе;
<li , т k> - термин [ связан с тематикой т k;
<Pj , т k> - термин-словокомплекс Pj связан с тематикой т k.
Тогда релевантность тематики тk оценивается по следующей формуле:
Rel(rk) = «k Xw(l.) + Р Xw(Pj) Pj|,
<1, ,zt >	<Pj ,zt >
где ak равняется мощности \{!,ею | <l,, т> е Y }|, т .е. количеству различных слов запроса, соответствующих данной тематике; Р - коэффициент степени важности терминов-слово-комплексов; w(l,) - вес однословного термина; w(pj) - вес термина-словокомплекса; pj\ - длина словокомплекса, равная количеству слов в его составе.
Веса терминов вычисляется по формулам:
w(t)=УА 1 , w( )=УеА i ,
Tl \Hom(li)|'W«V	'\Hom(Pj)|'
где у - функция, обратно пропорциональная степени универсальности термина; T, - множество тематик, приписанных термину в словаре; Hom(x) - множество терминов, пересекающихся в тексте с термином Х (что соответствует количеству омонимов Х).
В соответствии с приведенными формулами вес терминов включает постоянную часть, зависящую только от словаря, и переменную, зависящую от запроса. Постоянная часть веса термина (словокомплекса) зависит от следующих характеристик:
•	количество тематик, приписанных данному термину в словаре;
•	является ли термин «универсальным» - малозначимым с точки зрения эксперта или относящимся к большому количеству тематик (для этой цели в словаре введена специальная тема «_Универсальный» для пометки таких терминов);
•	в свою очередь переменная часть веса зависит от степени неоднозначности запроса (количества омонимов, состава терминов-словокомплексов и т. п.) и вычисляется заранее, на этапе построения тематического покрытия текста запроса.
Предлагается ввести следующие значения коэффициентов:
I 15 - если термин универсальный (universal term),
Р = 2, у = у 5
[1 - иначе.
Значения данных коэффициентов были проверены экспертным путем в результате тестирования, однако, очевидно что они могут варьироваться в зависимости от предметной области и организации рубрикатора и требуется разрабатывать автоматизированные методы подбора коэффициентов.
Оценка эффективности классификатора
Для тестирования предложенного подхода использовался рубрикатор, содержащий около 100 рубрик, которые соответствуют различным видам деятельности, реализуемой с помощью
веб-сайтов: «Аренда домов и квартир», «Ювелирный магазин», «Охранное агентство», «Металлообработка и металлопрокат», «Медицинский центр», «Веб-сайт художника», «Блог о путешествиях», «Организация по защите окружающей среды» и др. Содержание каждой рубрики отражено в ее наименовании и 5-10 подобранных экспертом ключевых словах.
Корпус тестовых запросов, использованных при оценке эффективности классификатора и характеристик тематических словарей, включал по 3-5 запросов по каждой теме (всего 368 запросов на русском языке и 330 на английском). Тексты из тестовой выборки можно условно разделить на дескрипции-заголовки (Пункт проката автомобилей, Доставка пиццы на дом, Фан-клуб группы Золотой век, Сайт живописца Ольги Ивановой, Бригада плотников в Н-ске, Сайт ИП, продажа и изготовление под заказ мягкой мебели) и прямые или косвенные директивы на базе глагольных конструкций (Создать сайт мотосалона, Хочу создать сайт для продажи женской одежды через Интернет).
Классификатор по заданному запросу выводил список всех тем, к которым он может быть отнесен. Результаты классификации для русского языка были разделены на семь типов.
R1. Единственный правильный ответ.
R2. Правильный ответ выигрывает с отрывом.
R3. Объективная неоднозначность (множественный альтернативный правильный ответ).
R4. Субъективная неоднозначность (несколько ответов, с одним правильным).
R5. Правильный ответ есть в выдаче, но проигрывает.
R6. Правильного ответа нет в выдаче.
R7. Пустая выдача.
При этом успешными или условно успешными можно считать только выдачи, относящиеся к первым трем категориям. Количественные характеристики эксперимента отражены в табл. 1. Как видно, классификатор показывает хорошие результаты на 82 % запросов тестовой выборки, что является достаточно высоким показателем для классификации сверхкоротких текстов.
При тестировании классификатора на англоязычных запросах использовались три градации качества классификации: E1) первое место в векторе претендентов на заданную тематику («хорошее» распознавание); E2) вхождение верного результата классификации в пятерку претендентов, начиная со 2-го места в результирующем векторе («удовлетворительная» классификация); E3) «плохая» классификация - отсутствие верного ответа в первой пятерке. Успешными и условно успешными можно считать выдачи, относящиеся к первым двум категориям. Результаты тестирования представлены в табл. 2.
Из табл. 2 следует, что классификатор удовлетворительно распознал тематику 75 % запросов тестовой выборки. Одной из причин более низкой, по сравнению с русскоязычной версией, эффективности классификатора является отсутствие морфологического анализа и лексико-синтаксических шаблонов словосочетаний в англоязычной версии словаря.
Программная реализация классификатора была выполнена на языке С++. Время инициализации программы-обработчика, включая загрузку словарей, насчитывающих 11 263 и 6 740 слов и словосочетаний, составило около 70 мс. Среднее время обработки одного запроса без инициализации составило около 0,1 мс. Производительность измерялась на процессоре Intel Core i3 в однопоточном режиме.
Таблица 1
Количественные характеристики результатов классификации для русского языка
Тип результата	R1	R2	R3	R4	R5	R6	R7	Всего
Количество ответов	80	200	23	42	14	4	5	368
Доля ответов, %	21,7	54,4	6,3	11,4	3,8	1	1,4	100
Таблица 2
Количественные характеристики результатов классификации для английского языка
Тип результата	E1	E2	E3	Всего
Количество ответов	151	96	83	330
Доля ответов, %	45,8	29,1	25,1	100
Заключение
В статье рассмотрены вопросы организации средств тематического анализа запросов пользователей, ориентированных на интернет-среду. Предложенные методы позволяют автоматизировать процесс разработки тематических словарей и настраивать их на определенную предметную область, жанр и тип текстов. Особое внимание уделено особенностям обработки и классификации коротких пользовательских запросов. Рассматриваемый подход позволяет расширить границы применимости методов классификации на сверхкороткие тексты даже в тех случаях, когда создание обучающей выборки является проблематичным.
Предложенный метод тематической классификации представляет, как нам кажется, разумный компромисс между трудоемкостью построения классификатора и его качеством. Отметим, что наиболее перспективным и эффективным оказался комплексный подход, совмещающий методы машинного обучения и лингвистические, ориентированные на экспертов, методы настройки словарей. Апробация подхода при разработке средств тематического анализа запросов в соответствии с рубрикатором видов деятельности в Интернете свидетельствуют об эффективности предлагаемой методики. Предложенные методы и инструменты, очевидно, применимы для различных предметных областей - оценка трудозатрат по экспертной настройке словаря при наличии необходимого инструментария составляет около двух человеко-месяцев на 100 рубрик.
Дальнейшее направление исследований связано с: а) автоматическим пополнением тематических словарей при наличии «обратной связи» с пользователями; б) приведением весов терминов в соответствие со статистикой запросов; в) углублением анализа микротекстов-запросов.
Список литературы
1.	Сегалович И. Как работают поисковые системы. URL: http://download. yandex. ru/ com-pany/iworld-3. pdf (дата обращения 30.10.2014).
2.	Романов А. С., Мещеряков Р. В. Определение пола автора короткого электронного сообщения // Компьютерная лингвистика и интеллектуальные технологии: По материалам ежегодной Междунар. конф. «Диалог-2011». М.: Изд-во РГГУ, 2011. Вып. 10 (17). С. 620-626. URL: http://www. dialog-21.ru/digests/dialog2011/materials/ru/pdf/55.pdf.
3.	Bo Pang, Lillian Lee, Shivakumar Vaithyanathan. Thumbs up? Sentiment Classification using Machine Learning Techniques // EMNLP. 2002. С. 79-86. URL: /http://www.cs.cornell.edu/ home/llee/papers/sentiment.pdf.
4.	Sebastiani F. Machine learning in automated text categorization // ACM Computing Surveys, 2002. Vol. 34, Is. 1. P. 1- 47. URL: http://nmis.isti.cnr.it/sebastiani/Publications/ACMCS02.pdf.
5.	Белов А. А., Волович М. М. Автоматическое распознавание тематики сверхкоротких текстов // Компьютерная лингвистика и интеллектуальные технологии: По материалам ежегодной Междунар. конф. «Диалог-2007» / Под ред. Л. Л. Иомдина, Н. И. Лауфер, А. С. На-риньяни, В. П. Селегея. М.: РГГУ, 2007. С. 35-38. URL: http://www.dialog-21.ru/digests/ dia-log2007/materials/html/05.htm.
6.	Cohen W. W., Singer Y. Context-Sensitive Learning Methods for Text Categorization // Proceedings of SIGIR-96, 19th ACM International Conference on Research and Development in Information Retrieval / ACM Press, N. Y., US, 1996. З. 307-315. URL: http://www.magicbroom. info/ Papers/CohenSi99.pdf.
7.	Riboni D. Feature Selection for Web Page Classification // EURASIA-ICT 2002, Proc. of Workshopю P. 473-478. URL: http://homes. di. unimi.it/riboni/eurasia02.pdf.
8.	Добров Б. В., Лукашевич Н. В. Автоматическая рубрикация полнотекстовых документов по классификаторам сложной структуры // VIII Нац. конф. по искусственному интеллекту КИИ-2002. М.: Физматлит, 2002. Т. 1. С. 178-186. URL: http://www. cir. ru/docs/ips/ publications/2002_cai_rubr.pdf/.
9.	Романов А. С., Мещеряков Р. В. Идентификация авторства коротких текстов методами машинного обучения // Компьютерная лингвистика и интеллектуальные технологии: По ма-
териалам ежегодной Междунар. конф. «Диалог». М.: Изд-во РГГУ, 2010, Вып. 9 (16). С. 407413. URL: http://www. dialog-21.ru/digests/dialog2010/materials/html/62.htm.
10.	Сидорова Е. А. Подход к построению предметных словарей по корпусу текстов // Тр. Междунар. конф. «Корпусная лингвистика - 2008». СПб.: СПбГУ, Факультет филологии и искусств, 2008. С. 365-372. URL: http://corpora.phil.spbu.ru/Works2008/Sidorova_365_372.pdf.
11.	Сокирко А. В. Морфологические модули на сайте www.aot.ru. URL: http://www.aot.ru/ docs/sokirko/Dialog2004.htm (дата обращения 30.10.2014).
12.	Антонова А. Ю., Клышинский Э. С., Ягунова Е. В. Определение стилевых и жанровых характеристик коллекций текстов на основе частеречной сочетаемости // Тр. Междунар. конф. «Корпусная лингвистика - 2011». СПб.: СПбГУ, Филологический факультет, 2011. С. 80-85. URL: http://corpora.phil.spbu.ru/Works2011/Антонова_80/pdf.
Материал поступил в редколлегию 02.12.2014
E. A. Sidorova 1 2, S. V. Anohin 1 2, I. S. Kononenko 1 2, N. V. Salomatina 1 3
1 Novosibirsk State University 2 Pirogov Str., Novosibirsk, 630090, Russian Federation
2	Institute of Informatics Systems
6Lavrentiev Ave., Novosibirsk, 630090, Russian Federation
3	Institute of Mathematics SB RAS
4 Koptyug Ave., Novosibirsk, 630090, Russian Federation
[email protected], [email protected], [email protected], [email protected]
THEMATIC ANALYSIS OF USER QUERIES BASED ON SUBJECT DICTIONARIES
The paper describes an approach to thematic categorization of short texts that is based on subject dictionaries of domain language vocabulary. The procedure of creating subject dictionary is proposed that involves the technique for learning the dictionary in the absence of adequate training sample of target texts. The proposed approach is illustrated by experiments aimed at assigning thematic categories to Internet user queries according to the subject headings of the rubricator of Internet activities. The categorization algorithm is presented and the results of experimental study discussed.
Keywords: query analysis, thematic analysis, short text categorization, subject dictionary, dictionary learning, relevance.
References
1.	Segalovich I. Kak rabotayut poiskovye sistemy? [How search engines work?]. URL: http://download.yandex.ru/company/iworld-3.pdf (accessed 30.10.2014).
2.	Romanov A. S., Meshcheryakov R. V. Opredelenie pola avtora korotkogo ehlektronnogo soobshcheniya [Gender identification of the author]. Computational Linguistics and Intelligent Technologies: Proceedings of the International Conference «Dialogue 2011», Moscow, 2011. p. 620-626. URL: http://www.dialog-21.ru/digests/dialog2011/materials/ru/pdf/55.pdf.
3.	Bo Pang, Lillian Lee, Shivakumar Vaithyanathan. Thumbs up? Sentiment Classification using Machine Learning Techniques. EMNLP, 2002, p. 79-86. URL: http://www.cs.cornell.edu/ home/llee/papers/sentiment.pdf
4.	Sebastiani F. Machine learning in automated text categorization. ACM Computing Surveys, Vol. 34, Is. 1, p. 1-47. URL: http://nmis.isti.cnr.it/sebastiani/Publications/ACMCS02.pdf.
5.	Belov A. A., Volovich M. M. Avtomaticheskoe raspoznavanie tematiki sverhkorotkih tekstov [Automatic Classification of Very Short Texts]. Computational Linguistics and Intelligent Technologies: Proceedings of the International Conference «Dialogue 2007», Moscow, 2007. p. 35-38. URL: http://www.dialog-21.ru/digests/dialog2007/materials/html/05.htm
6.	Cohen W. W. and Singer Y. Context-Sensitive Learning Methods for Text Categorization. Proceedings of SIGIR-96, 19th ACM International Conference on Research and Development in Information Retrieval, ACM Press, New York, US, 1996, p. 307-315. URL: http://www. magicbroom. info/ Papers/CohenSi99.pdf.
7.	Riboni D. Feature Selection for Web Page Classification. EURASIA-ICT 2002, Proc. of Workshop, p. 473-478. URL: http://homes.di.unimi.it/riboni/eurasia02.pdf
8.	Dobrov B. V., Lukashevich N. V. Avtomaticheskaya rubrikaciya polnotekstovyh dokumentov po klassifikatoram slozhnoj struktury [Automatic Categorization of Full-text Documents for Classifiers with Complex Structure]. Proceedings of the 8th National Conference on Artificial Intelligence CAI-2002, Moscow, 2002, Vol. 1, p. 178-186. URL: http://www.cir.ru/ docs/ips/publications/2002_cai_rubr.pdf.
9.	Romanov A. S., Meshcheryakov R. V. Identifikaciya avtorstva korotkih tekstov metodami mashinnogo obucheniya [Authorship Identification of Short Texts with Mashine Learning Techniques]. Computational Linguistics and Intelligent Technologies: Proceedings of the International Conference «Dialogue 2010», Moscow, 2010, p. 407-413. URL: http://www.dialog-21.ru/digests/dialog2010/materials/html/62.htm.
10.	Sidorova E. A. Podhod k postroeniyu predmetnyh slovarej po korpusu tekstov [Approach to Subject Dictionary Construction from Text Corpora]. Proceedings of International Scientific Conference «Corpus Linguistics-2008», St. Petersburg, 2008, p. 365-372. URL: http://corpora. phil.spbu.ru/Works2008/Sidorova_365_372.pdf.
11.	Sokirko A. V. Morfologicheskie moduli na sajte www.aot.ru [Morphological modules on www.aot.ru]. URL: http://www.aot.ru/docs/sokirko/Dialog2004.htm (accessed 30.10.2014).
12.	Antonova A. Yu., Klyshinskij E. S., YAgunova E. V. Opredelenie stilevyh i zhanrovyh harakteristik kollekcij tekstov na osnove chasterechnoj sochetaemosti [Identification of Style and Genre Characteristics of Text Collections Based on Part of Speech Compatibility]. Proceedings of International Scientific Conference «Corpus Linguistics-2011», St. Petersburg, 2011, p. 80-85. URL: http://corpora.phil.spbu.ru/Works2011/AHTOHOBa_80.pdf.
