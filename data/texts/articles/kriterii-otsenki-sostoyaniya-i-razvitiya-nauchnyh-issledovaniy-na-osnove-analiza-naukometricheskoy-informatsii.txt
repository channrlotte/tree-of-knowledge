От редакции
В прошлом году «Вопросы образования» открыли на страницах журнала дискуссию по выбору наукометрических и иных экспертных показателей для оценки продуктивности работы исследователей и научных организаций. Началась она с публикации фрагментов из оригинальной статьи Х. Хирша, а затем статьи питерских специалистов об использовании индекса Хирша в Российском индексе научного цитирования (РИНЦ). Сегодня к обсуждению присоединились представители научного сообщества Астраханского госуниверситета. В спор с ними вступает Павел Арефьев, руководитель рабочей группы в проекте РИНЦ, один из ведущих специалистов в области наукометрии.
220
Вопросы образования. 2015. № 2
Критерии оценки состояния и развития научных исследований на основе анализа наукометрической информации
Ю. Ю. Тарасевич, Т. С. Шиняева
Тарасевич Юрий Юрьевич
доктор физико-математических наук, профессор, заведующий лабораторией «Математическое моделирование и информационные технологии в науке и образовании» Астраханского государственного университета. E-mail: [email protected] Шиняева Таисия Сергеевна аспирант, младший научный сотрудник лаборатории «Математическое моделирование и информационные технологии в науке и образовании» Астраханского государственного университета. E-mail: danilova.taisiya@ gmail.com
Адрес: г. Астрахань, 414056, ул. Татищева, 20а.
Аннотация. Обсуждаются критерии оценки эффективности научных исследований. Анализируется выполнимость задачи разработать научно обоснованные методы, которые позволят оценить деятельность научных направ-
лений и научных коллективов. С точки зрения авторов, основой для проведения полномасштабных исследований динамики развития научных направлений и научных коллективов должны служить информационные системы текущих исследований (Current Research Information Systems, CRIS) организаций, интегрированные в национальную CRIS. Авторы предлагают методику оценки результативности текущих научных исследований, основанную на анализе престижа журналов, в которых опубликованы результаты исследований научного коллектива. Ключевые слова: науковедение, наукометрия, цитирования, самоцитирования, индекс Хирша, Web of Science, Scopus, РИНЦ, SJR, SNIP, информационные системы текущих исследований, рейтинговые оценки, эффективность научной деятельности, продуктивность научной деятельности.
DOI: 10.17323/1814-9545-2015-2-221-234
Статья поступила в редакцию в феврале 2015 г.
Научно обоснованные критерии анализа результативности и эффективности научных организаций и научных коллективов являются основой эффективного управления научной деятельностью. Проблема выработки таких критериев носит ярко выраженный междисциплинарный характер, так как находится на стыке наукометрии, классической статистики, информатики и управления; в последние годы для проведения наукометрических иссле-
http://vo.hse.ru
221
ДИСКУССИЯ
дований активно применяются методы статистической физики. Современное мировое состояние проблемы интеграции данных о результатах научной деятельности и их анализа можно найти в размещенных в свободном доступе материалах 12th International Conference of Current Research Information Systems (CRIS 2014), Rome, May 13th-15th, 2014 [Jeffery et al., 2014]. Отечественным проблемам анализа наукометрической информации и оценки результатов научной деятельности посвящен недавно вышедший сборник статей [Новиков, Орлов, Чеботарев, 2013].
Сегодня в России нет понятной государственной политики в оценке результатов научной деятельности. Предлагаемые во всевозможных отчетах индикаторы ориентируют исполнителей на производство показателей, а не научных результатов. Как следствие, наукометрические показатели рассматриваются как цель, а не как средство для оценки результатов научной деятельности. Нет понимания того, что только совокупность различных наукометрических показателей совместно с дополнительными данными является информационной основой для оценки результатов научной деятельности. Наукометрические показатели абсолютизируются и используются в отрыве от другой информации.
Проведение наукометрических исследований невозможно без наличия полной, своевременной и достоверной информации о результатах научной деятельности. Такую информацию можно получить только с использованием современных информационных систем. С учетом интернационального характера науки такие информационные системы должны обеспечивать сбор информации из различных международных и национальных баз данных. Несмотря на то что опыт проведения наукометрических исследований в нашей стране сопоставим с общемировым (ключевые работы Налимова и Гарфилда вышли почти в одно время [Налимов, Мульченко, 1969; Garfield, 1972]), сегодня имеется катастрофическое отставание России в наукометрии. Россия практически не интегрирована в организацию eurOCRIS1, общеевропейский формат исследовательской информации (CERIF)2, онтология VIVO3 почти не применяется. Информационные технологии слабо внедряются в поддержку научных исследований и анализ их результатов — подтверждением служат информационно-аналитические системы РФФИ* * * 4 *, РГНФ5, РНФ6, Мин-
1
2
3
4
5
6
http://www.eurocris.org/
http://www.eurocris.org/Index.php?page=CERIFintroduction&t=1
http://vivoweb.org/; http://ebiquity.umbc.edu/ontology/
http://kias.rfbr.ru
http://grant.rfh.ru
http://grant.rscf.ru
222
Вопросы образования. 2015. № 2
Ю. Ю. Тарасевич, Т. С. Шиняева Критерии оценки состояния и развития научных исследований
обрнауки7 8. Ни одна из этих систем не обеспечивает, например, импорт библиографических описаний публикаций по doi через CrossRef8; отсутствует возможность импорта метаописаний публикаций из Научной электронной библиотеки9, Российской книжной палаты10 11 12, буферной системы ORCID (Open Researcher and Contributor ID)11; не обеспечен ввод библиографических описаний в распространенных форматах BibTeX, RIS, по ГОСТ 7.1-2003 «Библиографическая запись» и ГОСТ Р 7.0.5-2008 «Библиографическая ссылка».
Информационные системы текущих исследований (Current Research Information Systems — CRIS) имеются у незначительного числа научных организаций. Национальная CRIS отсутствует. Проект «Карта российской науки»12 по глубине и широте используемой информации не может пока претендовать на статус национальной CRIS. Проект основан на предположении, что информацию о научных результатах отдельных ученых, научных коллективов и организаций можно собрать по принципу «сверху вниз». На практике же оказалось, что получаемая таким образом информация крайне неполная. Только сам исследователь владеет исчерпывающей информацией о своих результатах, поэтому ключевым принципом накопления данных о результатах научной деятельности должен быть принцип «снизу вверх», дополненный наполнением базы данных информацией из внешних источников.
Таким образом, основой для проведения полномасштабных исследований динамики развития научных направлений и научных коллективов должны служить CRIS организаций, интегрированные в национальную CRIS. Более детальное описание нашего видения проблемы можно найти в: [Данилова и др., 2014. С. 7-16].
Оценка результативности и эффективности научной деятельности должна базироваться на полной, достоверной и своевременной информации о результатах научной деятельности, которая накапливается в информационной системе текущих исследований организаций, интегрированных в национальную CRIS, обеспечивающую импорт информации из внешних источников (РИНЦ, Роспатент, ЦИТИС, Web of Science, Scopus, CrossRef и т. д.). Накопление информации о результатах научной деятельности должно быть максимально автоматизированным, обеспечивать верификацию данных и исключать их
7	http://dusp.ru
8	http://crossref.org
9	http://elibrary.ru
10	http://www.bookchamber.ru
11	http://orcid.org
12	http://mapofscience.ru/
http://vo.hse.ru
223
ДИСКУССИЯ
повторный ввод. Единожды введенная информация, например о публикациях ученого, должна быть открытой и обеспечивать возможность многократного использования, в частности в КИАС РФФИ, ИАС РНФ, ИС РГНФ, ИС формирования государственных заданий высшим учебным заведениям и научным организациям в сфере научной деятельности Минобрнауки РФ и т. д.
Предлагаемые методы, методики, инструментарий и их обоснование
Мы исходим из следующих принципиальных утверждений.
1.	Наукометрические показатели являются только информацией для анализа ситуации и принятия решения, а не окончательным диагнозом. В двух основных списках базы данных наиболее цитируемых российских ученых «Кто есть кто в российской науке»13 значатся 210 («Суммарное цитирование статей автора по ISI (WoS) — не менее 1000») и 148 («Цитирование статей автора, опубликованных в последние 7 лет, — не менее 100») академиков РАН. В оба списка сразу попали 126 академиков. На начало 2015 г. Российская академия наук насчитывала 463 академика. При этом в значениях индекса Хирша академиков РАН наблюдается большой разброс: от 6 до 70 (рис. 1).
2.	Только совокупность различных наукометрических показателей совместно с другой информацией может дать более или менее объективную характеристику текущего состояния и перспектив развития научного коллектива или направления. Информация, которую, запрашивает, например, Министерство образования и науки, включает, как правило, количество публикаций, количество цитирований, индекс Хирша. Сами по себе эти показатели неинформативны. Как минимум нужно учитывать долю самоцитирований и цитирований соавторами (рис. 2). Индекс Хирша должен сопоставляться с возрастом ученого и количеством опубликованных работ.
3.	Наукометрические показатели носят статистический характер, их применение для оценки отдельного ученого или небольшого коллектива может давать сколь угодно большую погрешность в любую сторону. Например, по данным РИНЦ, у одного автора за 2010-2014 гг. в среднем за год выходило 78 публикаций, при этом доля самоцитирований составляла около 75%, а доля цитирований соавторами — почти 95%, всего 864 публикации, индекс Хирша — 20, индекс Хирша без учета самоцитирований — 1014. При этом у академика РАН
13	http://www.expertcorps.ru/science/whoiswho
14	http://elibrary.ru/author_profile.asp?authorid=3132
224
Вопросы образования. 2015. № 2
Ю. Ю. Тарасевич, Т. С. Шиняева Критерии оценки состояния и развития научных исследований
Рис. 1. Индексы Хирша академиков из списка «Цитирование статей автора, опубликованных в последние 7 лет, — не менее 100»
Рис. 2. Данные десяти сотрудников Астраханского государственного университета, имеющих, по данным РИНЦ, наибольшее число цитирований
■	Число цитирований
■	Число цитирований соавторами
■	Число самоцитирований
http://vo.hse.ru
225
ДИСКУССИЯ
Е. Н. Аврорина, по данным РИНЦ, всего 46 статей и индекс Хирша равен 7, а у выдающегося российского математика Григория Перельмана отсутствуют профили в системах Scopus и elibrary.
4.	Наука интернациональна. Применение локальных и национальных критериев («Список ВАК») дезориентирует ученых, способствует изоляции науки. По данным РИНЦ, 2228 российских журналов входят в перечень ВАК. Более 46% из них (1034 журнала) имеют импакт-фактор РИНЦ менее 0,1. Менее 1% (21 журнал) имеют импакт-фактор РИНЦ выше 1. У ряда российских ученых с высокими показателями РИНЦ нулевые или почти нулевые показатели в Scopus. Например, у автора по данным РИНЦ число публикаций 182, число цитирований 1027, индекс Хирша 815, а по данным Scopus число публикаций 2, число цитирований 0, индекс Хирша 01е.
5.	Невозможно выработать единые формальные показатели, которые одинаково хорошо работали бы для оценки научной результативности и эффективности в разных научных направлениях, в фундаментальной и прикладной науке. Применение одних и тех же критериев для оценки результативности научной деятельности ошибочно, так как гарантированно будет демонстрировать мнимую неэффективность отдельных направлений, которые не вписываются в унифицированные критерии [Шиняева, Седышева, Тарасевич, 2015].
6.	Система текущей рейтинговой оценки результативности и эффективности научной деятельности должна базироваться на принципах научной этики17, ориентировать исследователей на получение научных результатов мирового уровня, а не на производство показателей. В частности, система оценок должна подавлять «нарезку салями», фиктивное авторство, публикации в «дружественных» журналах. Для сдерживания фиктивного авторства можно использовать учет в рейтинге публикаций числа соавторов. Однако применять данный подход следует крайне осторожно, так как типичное число соавторов существенно различается в различных науках — от одного (философия) до нескольких сотен (физика высоких энергий). Проблема учета вклада соавторов в результат научной деятельности не имеет простого решения. Традиции построения списка авторов в России и за рубежом различаются. На Западе идеолог работы (руководитель группы) зачастую идет в списке последним, в России — первым. В нашей стране часто можно встретить списки авторов, по-
15	http://elibrary.ru/author_profile.asp?authond=63506
16	http://www.scopus.com/authid/detail.url?authorId=6508298138
17	Publishing Ethics Resource Kit http://www.elsevier.com/editors/perk
226
Вопросы образования. 2015. № 2
Ю. Ю. Тарасевич, Т. С. Шиняева Критерии оценки состояния и развития научных исследований
Рис. 3. Распределение публикаций и статей в журналах по годам http://elibrary.ru/author_proflle_years.asp?id=91563
400
350
300
250
200
150
100
50
0
2005	2006	2007	2008	2009	2010	2011	2012	2013	2014
■	Статьи в журналах
■	Публикации
строенные по принципу: самый большой начальник (руководитель организации), имеющий к работе очень косвенное отношение, — большой начальник (заместитель руководителя), имеющий к работе столь же малое отношение, — начальник (руководитель отдела), который что-то слышал о работе или даже одобрил ее выполнение, — реальные авторы. Порой список выстраивается по алфавиту. При выполнении равноправных частей работы разными группами вопрос справедливого упорядочения авторов по степени участия вообще сложно разрешим. Оригинальным примером решения этой проблемы служит все чаще встречающееся прямое указание в примечании к списку авторов: «Все авторы внесли равный вклад». Порой даже сами соавторы затрудняются определить реальный вклад каждого из участников работы. Вывод: грубый подсчет путем деления рейтинга на число авторов может оказаться более справедливым, чем вариант весов (см., например, [Abbas, 2011; Vinkler, 2010. P. 154-159]).
7.	Оценки результативности научной деятельности должны учитывать предел интеллектуальных и физических возможностей человека. 300 публикаций за год говорят не о научных результатах ученого, а о том, что он — директор института, и сотрудники автоматически включают его во все публикации, безотносительно к реальному вкладу в полученные результаты (рис. 3). Сомнительно, что этот автор мог внести существенный вклад в интерпретацию полученных результатов, а именно это, согласно принципам публикационной эти-
http://vo.hse.ru
227
ДИСКУССИЯ
Рис. 4. Распределение статей автора за 2012 г. по журналам
(http://elibrary.ru/authorJtems.asp?authorid=231418).
В скобках на легенде указан импакт-фактор РИНЦ без учета самоцитирований. Наибольшее количество статей (70%) в двух журналах, принадлежащих одной организации. Общее число статей за год составило 24, средний объем статьи — 6,5 страницы
Перспективы развития строительного комплекса
(0,124) 4,17%
Естественные науки (0,196) 33,33%
Прикаспийский журнал: управление и высокие технологии (0,702) 37,5%
ки [Тарасевич, 2014], является основанием для включения кого-либо в число соавторов.
8.	В оценке текущей публикационной и иной научной активности должен быть предусмотрен эффект насыщения. Например, после 10 статей за год вклад каждой статьи в копилку должен стремительно снижаться до 0, т. е. человек, опубликовавший за год 100 статей, должен получить нулевой рейтинг.
9.	Система оценки текущей публикационной активности должна включать систему штрафов за многократную публикацию в течение года статей в одном и том же журнале с низким рейтингом (публикации в «дружественных» журналах) (рис. 4).
10.	Количество охранных документов на объекты интеллектуальной собственности не может служить критерием научной результативности и эффективности. Таким критерием может быть подтвержденный экономический и социальный эффект от использования этих объектов. На рис. 5 представлено распределение публикаций одного из авторов научной электронной библиотеки elibrary.ru по числу цитирований. Более 23 тыс. публикаций зарегистрировано у данного автора, подавляющее большинство из них — патенты, на 21 869 из которых нет ни одной ссылки. 4014 патентов на изобретения получены одним человеком без соавторов в 2009 г., т. е. каждые два часа без сна и выходных человек выдает по изобретению. Почти такая же удивительная производительность труда наблюдается у этого автора и в другие годы (рис. 6).
228
Вопросы образования. 2015. № 2
Ю. Ю. Тарасевич, Т. С. Шиняева Критерии оценки состояния и развития научных исследований
Рис. 5. Распределение публикаций по числу цитирований (доля самоцитирований составляет 96,4%) http://elibrary.ru/ author_items.asp?authorid=144259
Количество
0	1	2	3	4	5	6	7
Количество цитирований
Рис. 6. Распределение патентов по годам
http://elibrary.ru/author_items.
asp?authorid=144259
Количество
11.	Наукометрия не может оценивать научный уровень исследований. Наукометрия оценивает вовлеченность ученого или научного коллектива в мировой процесс обмена научной информацией. Значимость сегодняшних результатов для науки зачастую можно оценить только через десятилетия.
Публикационный рейтинг science.aspu.ru vs показатели РИНЦ и Scopus
Полная выборка составила 19 человек. В табл. 1 приведены некоторые показатели публикационной активности выбранных сотрудников по данным РИНЦ:
•	id — идентификатор пользователя;
•	статьи — количество публикаций типа «статья в журнале»;
На основании данных научной электронной библиотеки elibrary.ru мы отобрали по десять сотрудников Астраханского государственного университета, обладающих наивысшими показателями:
1)	по числу публикаций по данным РИНЦ;
2)	по числу цитирований по данным РИНЦ;
3)	по индексу Хирша РИНЦ.
http://vo.hse.ru
229
ДИСКУССИЯ
Таблица 1. Показатели РИНЦ и Scopus
vs рейтинг автора в системе science.aspu.ru (20.10.2014 г.)
РИНЦ
id	Статьи	Индекс Хирша без учета самоцитирований	Средний ИФ	Доля самоцитирований /цитирований соавторами, %	Среднее число ссылок на одну статью
149085	37	9	0,748	9,4 / 11,5	11,47
456167	106	5	0,44	25,1 / 84,8	0,47
174591	98	4	0,369	39,4 / 87,7	0,39
289518	19	3	0,785	14,8 /18,5	2,44
643440	19	1	0,455	38,7 / 100,0	0
63506	167	5	0,151	60,5 / 82,4	0,99
338812	53	2	0,32	69,9 / 86,3	0,14
616208	63	3	0,156	72,4 / 87,6	0,72
599016	ГО со	3	0,247	44,0 / 82,0	0,47
231418	135	5	0,177	47,9 / 96,4	0,13
157576	53	6	0,134	27,4 / 30,9	2,39
123654	121	4	0,229	23,1 / 59,3	0,55
280533	165	3	0,121	70,3 / 77,2	0,35
86224	185	4	0,1	55,5 / 83,6	0,39
530581	121	4	0,128	38,1 / 77,3	0,42
175388	73	2	0,073	73,1 / 85,9	0,14
120964	72	3	0,122	55,8 / 93,5	0,11
588682	71	4	0,137	42,4 / 98,4	0,04
621286	59	4	0,071	46,5 / 93,3	0,29
•	индекс Хирша без учета самоцитирований — индекс Хирша РИНЦ без учета самоцитирований;
•	средний ИФ — средневзвешенный импакт-фактор журналов, в которых были опубликованы статьи;
•	доля самоцитирований / цитирований соавторами;
•	среднее число ссылок на одну статью — число цитирований без соавторов РИНЦ, деленное на количество публикаций РИНЦ;
а также по данным Scopus:
•	id — идентификатор пользователя;
230
Вопросы образования. 2015. № 2
Ю. Ю. Тарасевич, Т. С. Шиняева Критерии оценки состояния и развития научных исследований
science.aspu.ru	Scopus
Рейтинг автора	Статьи	id	Публикации	Индекс Хирша без учета самоцитирований	Среднее число ссылок на одну статью
8,523	48	7102894155	ГО CD	8	5,19
2,599	О ГО	6701869651	41	3	0,63
2,184	107	6603030619	39	3	0,79
1,932	17	7801466084	12	2	1,08
0,419	29	42261798900	9	1	0,11
0,41	135	6508298138	0	0	0
0,334	58	6603248711	18	1	0,33
0,253	60	-	-	-	-
0,218	34	6507604818	9	3	1,78
0,215	ГО со	-	-	-	-
0,185	57	55595877300	3	0	0
0,161	173	6603962335	сл го	2	0,23
0,156	112	-	-	-	-
0,13	154	55221009800	1	0	0
0,102	118	6603085991	10	1	0,5
0,087	67	16204044400	3	1	0,67
0,06	65	55999755200	1	0
0,052	CD ГО	-	-	-	-
0,044	50	-	-	-	-
•	публикации — число публикаций;
•	индекс Хирша без учета самоцитирований — индекс Хирша Scopus без учета самоцитирований;
•	среднее число ссылок на одну статью — число цитирований без соавторов, деленное на количество публикаций;
и по данным scince.aspu.ru:
•	статьи — количество публикаций типа «статья в журнале»;
•	рейтинг автора.
Данные таблицы отсортированы в порядке убывания показателя «рейтинг автора science.aspu.ru».
http://vo.hse.ru
231
ДИСКУССИЯ
Рейтинг автора [Тарасевич, 2014] рассчитывается по формуле:
где N — количество статей автора; F. — импакт-фактор WoS журнала, в котором была опубликована i-я статья; N—число страниц i-й статьи; TNRi—типичное число страниц (10); NCAi — количество соавторов i-й статьи. Если у журнала отсутствует импакт-фактор WoS, приписываем данному журналу аналог импакт-факто-ра, рассчитываемый Scimago [Шиняева, Седышева, Тарасевич, 2015]. Когда и такого показателя не оказывается, импакт-фактор принимаем равным 0,01, если журнал индексируется WoS или Scopus, и 0,005 — если он индексируется РИНЦ. Во всех прочих случаях импакт-фактор принимаем равным 0,001.
Цветом в столбцах выделены ячейки с наивысшими показателями: наибольшее число публикаций, наивысший индекс Хирша и т. д. В столбце «доля самоцитирований / цитирований соавторами» выделены ячейки с долей самоцитирований не более 15%. В столбце «среднее число ссылок на одну статью» выделены ячейки со значениями, превышающими единицу.
По основным показателям РИНЦ (число публикаций, число цитирований, индекс Хирша без учета самоцитирований) в десятку лидеров попали шесть человек. Все они имеют высокую долю цитирования соавторами (более 77%).
У 40% авторов из выборки доля самоцитирований превышает 50%, а у 70% авторов доля цитирований соавторами превышает 80%.
Наибольший рейтинг у автора с наибольшим индексом Хирша РИНЦ и Scopus без учета самоцитирований, с высоким средним импакт-фактором РИНЦ и с наименьшей долей самоцитирований и цитирований соавторами. При этом количество публикаций у него на порядок ниже наивысших показателей.
Автор с идентификатором РИНЦ 157576 — один из трех авторов в нашей выборке, имеющих в среднем больше одной ссылки на статью. Однако он не попадает в десять лучших по рейтингу science.aspu.ru.
По нашей методике был рассчитан публикационный рейтинг Кунина Е. В. — российского ученого с наибольшим индексом Хирша по данным проекта «Корпус экспертов по естественным наукам»18. Данные для расчета рейтинга были взяты из базы данных Scopus (выходные данные статей в журналах) и с официальных сайтов журналов, в которых публиковался данный автор (импакт-фактор) (рис. 7).
18 http://expertcorps.ru/
i = 1
232
Вопросы образования. 2015. № 2
Ю. Ю. Тарасевич, Т. С. Шиняева Критерии оценки состояния и развития научных исследований
Рис. 7. Зависимость от времени импакт-фактора, публикационного рейтинга и рейтинга автора Кунина Е. В.
3500
3000
2500
2000
1500
1000
500
Rating -
Author rating * ^
★ *«- 800
★ ♦
★ 1 ★ * - *
★ ♦
t*. *
♦ •
♦ •
★
0
1980
700
600
500
400
300
200
100
0
1985
1990
1995
2000
2005
2010
2015
Нами предложена методика оценки результативности текущих научных исследований, основанная на анализе престижа журналов, в которых опубликованы результаты работ научного коллектива. В идеале методика должна основываться на единой шкале престижа научных изданий — от тезисов до монографий. Такая единая шкала должна хорошо коррелировать с распространенными наукометрическими показателями. Проблема заключается в том, что только незначительная часть изданий имеет признаваемый большей частью научного сообщества количественный индикатор научного престижа — импакт-фактор. Только малая часть работ российских ученых публикуется в журналах, имеющих импакт-фактор. При этом импакт-факторы РИНЦ для отечественных переводных журналов плохо коррелируют с импакт-факторами Web of Science и рассчитываемой по той же методике на основании данных Scopus величиной Cite/Doc. 2 year [Шиняева, Седышева, Тарасевич, 2015]. Методика дополнительно учитывает число соавторов и объем публикации, не стимулируя при этом графоманию.
1.	Данилова Т. С., Зелепухина В. А., Бурмистров А. С., Тарасевич Ю. Ю. Информационно-аналитическая система для сбора, хранения и анализа научной и наукометрической информации. Руководство пользователя. Астрахань: ООО «Типография Новая Линия», 2014. http://scien-ce.aspu.ru/index.php/files/download/715
★	IF
•	Rating
♦	Author rating
Результаты
исследования
Литература
http://vo.hse.ru
233
ДИСКУССИЯ
2.	Налимов В. В., Мульченко З. М. Наукометрия. Изучение науки как информационного процесса. М.: Наука, 1969.
3.	Новиков Д. А., Орлов А. И., Чеботарев П. Ю. (ред.) (2013) Управление большими системами: сб. трудов. Спец. выпуск № 44 «Наукометрия и экспертиза в управлении наукой»: М.: ИПУ РАН. http://ubs.mtas.ru/ archive/search_results_new.php?publication_id=19079
4.	Тарасевич Ю. Ю. Наукометрическая информация и ее анализ // Информатизация образования и науки. 2014. № 2 (22). С. 141-148.
5.	Шиняева Т. С., Седышева В. С., Тарасевич Ю. Ю. Коррелируют ли наукометрические показатели отечественных научных журналов, рассчитанные различными организациями? // Информатизация образования и науки. 2015. № 1 (25). С. 55-71.
6.	Abbas A. M. (2011) Weighted Indices for Evaluating the Quality of Research with Multiple Authorship // Scientometrics. Vol. 88. No 1. P. 107-131 DOI 10.1007/s11192-011-0389-7.
7.	Garfield E. (1972) Citation Analysis as a Tool in Journal Evaluation // Science. Iss. 178. P. 471-479.
8.	Jeffery K., Clements A., De Castro P., Luzi D. (eds) (2014) 12th International Conference on Current Research Information Systems, CRIS 2014. Managing Data Intensive Science. The Role of Research Information Systems in Realising the Digital Agenda //Procedia Computer Science. Vol. 33. P. 1-326 http://www.sciencedirect.com/science/journal/18770509/33
9.	Vinkler P. (2010) The Evaluation of Research by Scientometric Indicators. Oxford: Chandos Publishing. P. 154-159.
234
Вопросы образования. 2015. № 2
Ю. Ю. Тарасевич, Т. С. Шиняева Критерии оценки состояния и развития научных исследований
Библиометрия подобна футболу, политике и погоде: все знают, про что это, все досконально понимают, как это устроено, и все с любопытством наблюдают за этим — математики, физики, биологи, историки, философы, электронщики, айтишники, экономисты.
Справедливости ради стоит отметить, что десакрализация наукометрического действа, профанный, непрофессиональный взгляд на проблему порой приносили добрые плоды: физик Хорхе Хирш разработал замечательную метрику для оценки эффективности публикационной деятельности ученого.
Ю. Ю. Тарасевич и Т. С. Шиняева, также не будучи специалистами в наукометрии, поднимают тему, которая тянет не на одну и даже не на десяток журнальных статей: как определить уровень развития научных исследований на основе библиометрического анализа и получаемых через него данных. Авторы пытаются методологически обосновать «возможность разработки научно обоснованных методов оценки деятельности научных направлений и научных коллективов». Более того, они такую методику разрабатывают и представляют ее на суд читателей — «методику оценки результативности текущих научных исследований, основанную на анализе престижа журналов, в которых опубликованы результаты научных исследований научного коллектива».
Совершенно обоснованно авторы критикуют организационную структуру и менеджмент отечественной науки, который до сих пор не сформулировал четко и конкретно основы научной политики в России. «Стратегия развития 2015» сменяется «Стратегией-2020», на горизонте уже маячит «Стратегия-2030», но внятности в оценке результатов научной деятельности как не было, так и нет по сей день. О какой осмысленности в управлении наукой можно говорить, когда проекту «Российский индекс научного цитирования» в этом году исполняется 10 лет, но уже третий год подряд тот же самый государственный заказчик пытается разрабатывать другой, альтернативный РИНЦ проект по учету и анализу научных достижений России — «Карту российской науки». К слову сказать, РИНЦ пока что выглядит предпочтительнее «Карты» — и по общему объему обрабатываемых данных, и по методическому оснащению, и по индикаторам, и по динамике развития.
Ряд образовательных и научных организаций страны, в том числе МГУ, СПБГУ, НГУ, ТПУ, РУДН, ИТМО, УРФУ, уже не первый год используют в своей деятельности инструменты, о которых говорят авторы статьи, — системы управления научными исследованиями. Но разговоры на тему интеграции отдельных информационных систем текущих исследований (CRIS) в национальную систему пока остаются разговорами, в этом авторы
Комментарий П. Г. Арефьева,
руководителя рабочей группы в проекте РИНЦ (с 2005 по 2012 г.), главного специалиста Национального фонда подготовки кадров
http://vo.hse.ru
235
ДИСКУССИЯ
абсолютно правы. Невозможно не разделить уверенность авторов в том, что «наукометрия не может оценивать научный уровень исследований, наукометрия оценивает вовлеченность ученого или научного коллектива в процессы научной коммуникации и информационного обмена».
Весьма любопытен опыт локальной системы управления наукой в Астраханском государственном университете. Правда, о самой CRIS-системе авторы не пишут, а лишь приводят данные, индикаторы и метрики, по которым оцениваются объекты библиометрического анализа — отдельные ученые и научные коллективы.
В остальном статья построена на весьма тривиальных и расхожих заключениях, характерных как раз для неспециалистов, когда они рассуждают о проблемах оценки научных результатов и публикационной деятельности ученых. Во-первых, у авторов, конечно же, нет начитки, нет «навигационного опыта» ориентирования в публикационном потоке, который производится в затрагиваемой области. Маленький пример: только по CRIS насчитывается не менее 15 десятков опубликованных работ на английском языке, правда, 70% — это труды конференций.
Авторы, к сожалению, не отдают себе отчета в том, что наукометрия — это не исключительно статистическая дисциплина, она развивалась в основном благодаря положениям функциональной социологии, в частности социологии знания — это Роберт Мертон и компания. Именно Мертон и оказал решающее влияние на Гарфилда, когда тот решал проблемы с разработкой первого индекса цитирования в конце 1950-х — начале 1960-х годов. Поэтому в наукометрии всегда необходимы социологические интерпретации библиометрических фактов. В таком случае становится понятно, что академик РАН Е. Н. Аврорин и не мог быть автором значительного числа статей, опубликованных в ведущих журналах мира: академик всю жизнь проработал в Челябинске-70, ныне Снежинске. Какая в ЗАТО big science? Там сплошной «первый уровень доступа». А вот графоманы — публикационный из новокузнецкого вуза с 800 публикациями и 70%-ным уровнем самоцитирования и патентный с 24 тысячами заявок и свидетельств. Благодаря РИНЦ вся их деятельность раскладывается аккуратно по библиометрическим полочкам и становится очевидно, что «король-то голый». Да, на национальную CRIS РИНЦ, безусловно, еще пока не тянет. Но для разбора деятельности авторов уже вполне пригоден. РИНЦ дает возможность точно определить, где ученый сам пишет, где использует административный ресурс, а где у ученого откровенно не все в порядке с головой.
Зато гордость отечественной математики Григорий Перельман представлен вполне адекватно: гений публиковался в журналах, сборниках, трудах конференций чрезвычайно редко, в Ar-
236
Вопросы образования. 2015. № 2
Ю. Ю. Тарасевич, Т. С. Шиняева Критерии оценки состояния и развития научных исследований
xiv.org были обнаружены и выдвинуты на медаль Филдса его неопубликованные работы.
И последнее замечание, которое имеет отношение к методике оценки результативности текущих научных исследований. Из таблицы, где значения показателей из РИНЦ и Scopus сравниваются с системой science.aspu.ru, видно, что данные по большому счету коррелируют, особенно РИНЦ и science.aspu.ru. Но вот согласиться с тем, что авторы пишут в заключении к своей работе, сложно: «Методика должна основываться на единой шкале престижа научных изданий — от тезисов до монографий. Такая единая шкала должна хорошо коррелировать с распространенными наукометрическими показателями. Проблема заключается в том, что только незначительная часть изданий имеет признаваемый большей частью научного сообщества количественный индикатор научного престижа — импакт-фактор. Только малая часть работ российских ученых публикуется в журналах, имеющих импакт-фактор. Импакт-факторы РИНЦ для отечественных переводных журналов плохо коррелируют с импакт-факторами Web of Science и рассчитываемой по той же методике на основании данных Scopus величиной Cite/Doc. 2 year». Здесь опять сказывается отсутствие у авторов опыта социологических интерпретаций библиометрических фактов.
1.	А возможно ли построить такую шкалу престижа для всех типов изданий? Конечно, нет. Именно монографии первыми «не встанут» на этой шкале, а тезисы вообще не стоит учитывать. Не поддаются оценке авторитетности через среднюю цитируе-мость все книжные издания, не только монографии. У них нет и не может быть периодичности, что есть необходимое условие для «онтологического обоснования бытия» импакт-фак-тора.
2.	Значения импакт-фактора, рассчитанные для российских переводных версий в РИНЦ, разумеется, должны отличаться от соответствующих значений в Web of Science и Scopus. Дело не в нюансах расчетов. Дело в системе журнальной коммуникации: кто цитирует российские переводные издания и где, в каких журналах это цитирование отражается. Массив журналов РИНЦ по определению отличается от массива Web of Science и Scopus — и не только количественно, но и качественно. Отсюда и разница в значениях IF.
Несколько наивной представляется и рестриктивная часть предлагаемой авторами системы оценки результативности текущих научных исследований. Например, «система штрафов за многократную публикацию в течение года статей в одном и том же журнале с низким рейтингом (публикации в „дружественных" журналах)». Не надо придумывать ограничения, надо изначально выстраивать логически правильную систему, в которой участники
http://vo.hse.ru
237
ДИСКУССИЯ
не будут вынуждены выкручиваться, а будут вести себя органично. Для этого нужно сделать одну простую вещь: отделить учет научных результатов от анализа научных достижений. И дать возможность публиковаться в архиве открытого доступа типа Arxiv. org для фиксации своих научных трудов. А в журнале надо публиковать достижения, которые оцениваются.
238
Вопросы образования. 2015. № 2
DISCUSSION
Criteria for Assessment of Current Condition and Development of Research Studies Based on Scientometric Data Analysis
Yury Tarasevich
Doctor of Sciences in Mathematical Physics, Professor, Head of Laboratory “Mathematical Modelling and IT in Science and Education”, Astrakhan State University. Email: [email protected]
Taisiya Shinyaeva
Ph.D. student, Junior Researcher, Laboratory “Mathematical Modelling and IT in Science and Education”, Astrakhan State University. Email: [email protected]
Address: 20a Tatishcheva str., 414056, Astrakhan, Russian Federation.
The article reviews criteria for scientific research performance assessment. It analyzes feasibility of the task to develop scientifically based methods that would allow assessment of activities performed by individual research departments and teams. The authors believe that a full-scale study of the dynamics of scientific departments and teams development should be based on the Current Research Information Systems (CRIS) within companies integrated into the national CRIS. The authors suggest a method to assess performance of the ongoing research studies based on the review of ratings of journals on which a research team's studies are published.
research studies, scientometrics, citing, self-citing, Hirsch index, Web of Science, Scopus, RSCI (Russian Science Citation Index), SJR, SNIP, Current Research Information Systems, rating assessment, research performance, research productivity.
Abbas A. M. (2011) Weighted Indices for Evaluating the Quality of Research with Multiple Authorship. Scientometrics, vol. 88, no 1, pp. 107-131. doi: 10.1007/ s11192-011-0389-7.
Danilova T., Zelepukhina V., Burmistrov A., Tarasevich Y. (2014) Informatsion-no-analiticheskaya sistema dlya sbora, khraneniya i analiza nauchnoy i nau-kometricheskoy informatsii. Rukovodstvo polzovatelya [Information and Analytical System for Collection, Storage and Analysis of Scientific and Scientometric Information. User Manual]. Astrakhan: Tipografiya Novaya Lini-ya, LLC. Available at: http://science.aspu.ru/index.php/files/download/715 (accessed 10 April 2015).
Garfield E. (1972) Citation Analysis as a Tool in Journal Evaluation. Science, iss. 178, pp. 471-479.
Jeffery K., Clements A., De Castro P., Luzi D. (eds) (2014) 12th International Conference on Current Research Information Systems, CRIS 2014. Managing Data Intensive Science. The Role of Research Information Systems in Realising the Digital Agenda. Procedia Computer Science, vol. 33, pp. 1-326. Available at: http://www.sciencedirect.com/science/journal/18770509/33 (accessed 10 April 2015).
Nalimov V., Mulchenko Z. (1969) Naukometriya. Izuchenie naukikakinformatsion-nogo protsessa. [Scientometrics. Study of Science as an Information Process]. Moscow: Nauka.
Novikov D., Orlov A., Chebotarev P. (eds) (2013) Upravlenie bolshimi sistemami. Sbornik trudov. Spetsialny vypusk No 44. Naukometriya i ekspertiza v uprav-
Author
Abstract
Keywords
References
http://vo.hse.ru/en/
239
DISCUSSION
lenii naukoy [Managing Large-Scale Systems. Collection of articles. Special issue 44. Scientometrics and Expertise in Scientific Management]. Moscow: Institute of Control Sciences. Available at: http://ubs.mtas.ru/archive/ search_results_new.php?publication_id=19079 (accessed 10 April 2015).
Shinyaeva T., Sedysheva V., Tarasevich Y. (2015) Korreliruyut li naukometrich-eskie pokazateli otechestvennykh nauchnykh zhurnalov, rasschitannye ra-zlichnymi organizatsiyami? [Scientometric Indicators of Russian Scientific Journals Calculated by Different Organizations: Do They Correlate?] Infor-matizatsiya obrazovaniya i nauki, no 1 (25), pp. 55-71.
Tarasevich Y. (2014) Naukometricheskaya informatsiya i eyo analiz [Scientometric Information and Its Analysis]. Informatizatsiya obrazovaniya i nauki, no 2 (22), pp. 141-48.
Vinkler P. (2010) The Evaluation of Research by Scientometric Indicators. Oxford: Chandos Publishing.
240
Educational Studies. Moscow. 2015. No 2
