УДК 001.38 + 002 ББК 72.4+73.4
МОЖНО ЛИ ОЦЕНИВАТЬ ТРУД УЧЕНЫХ ПО БИБЛИОМЕТРИЧЕСКИМ ПОКАЗАТЕЛЯМ?
Москалева О. В.1
(Санкт-Петербургский государственный университет)
Рассматриваются основные библиометрические показатели и возможность их использования для оценки научно-исследовательской деятельности. Особое внимание уделяется особенностям применения библиометрических показателей для разных уровней анализа: на уровне стран, организаций, отдельных ученых, а также использованию аналитических инструментов InCites и SciVal Spotlight для сравнительной оценки научных исследований. Описываются проблемы, связанные с оценкой эффективности научной деятельности.
Ключевые слова: результат научного исследования, эффективность труда, библиометрия.
1.	Введение
Для того чтобы определиться, можно ли оценивать труд ученых по библиометрическим показателям, разберемся в первую очередь с терминологией.
Первое - что следует понимать под эффективностью труда ученого?
Экономический словарь определяет эффективность как относительный эффект, результативность процесса, операции, проекта, определяемые как отношение эффекта, результата к затратам, расходам, обусловившим, обеспечившим его получение. Далее встает вопрос о том, что же является результатом работы ученого. Это уже зависит от того, какими исследования-
1	Ольга Васильевна Москалева, кандидат биологических наук ([email protected]. ru).
ми занимается данный ученый. Для определения ясности в этом отношении обратимся к Федеральному закону от 23 августа 1996 года № 127-ФЗ «О науке и государственной научнотехнической политике». В статье 2 «Основные понятия, применяемые в настоящем Федеральном законе», читаем:
«Научная (научно-исследовательская) деятельность (далее -научная деятельность) - деятельность, направленная на получение и применение новых знаний, в том числе:
•	фундаментальные научные исследования - экспериментальная или теоретическая деятельность, направленная на получение новых знаний об основных закономерностях строения, функционирования и развития человека, общества, окружающей среды;
•	прикладные научные исследования - исследования, направленные преимущественно на применение новых знаний для достижения практических целей и решения конкретных задач.
•	Экспериментальные разработки - деятельность, которая основана на знаниях, приобретенных в результате проведения научных исследований или на основе практического опыта, и направлена на сохранение жизни и здоровья человека, создание новых материалов, продуктов, процессов, устройств, услуг, систем или методов и их дальнейшее совершенствование.
Научный и (или) научно-технический результат - продукт научной и (или) научно-технической деятельности, содержащий новые знания или решения и зафиксированный на любом информационном носителе.
Научная и (или) научно-техническая продукция - научный и (или) научно-технический результат, в том числе результат интеллектуальной деятельности, предназначенный для реализации».
Исходя из этого, следует, что библиометрические показатели могут, в принципе, применяться только для тех областей научной или научно-технической деятельности, результаты которых описываются в научных статьях или иных научных
публикациях, т.е. преимущественно для фундаментальных исследований и в какой-то мере для прикладных научных исследований, но не для разработок. Для этих областей деятельности более адекватным измерителем будут патенты или какие-либо иные практические результаты, которые по значимости для оценки сравнимы с научными статьями или монографиями, но не поддаются стандартными методам библиометрического анализа.
В связи с этим в дальнейших рассуждениях речь пойдет в основном об оценке результатов или оценке эффективности именно фундаментальных исследований.
2.	Основные библиометрические показатели и их применимость
2.1.	КОЛИЧЕСТВЕННЫЕ ПОКАЗАТЕЛИ РЕЗУЛЬТАТИВНОСТИ
В первую очередь рассмотрим, что следует, а что не следует учитывать при оценке труда ученого или научного коллектива.
Если принять за аксиому, что научная статья пишется для того, чтобы донести полученный научный результат до научной общественности с целью его использования или анализа максимально большим количеством ученых, работающих по сходной тематике, то первым критерием будет возможность этого самого научного сообщества ознакомиться с опубликованным результатом.
Где и как можно опубликовать результат исследования?
1.	В профильном научном журнале.
2.	В тематическом сборнике статей.
3.	В виде тезисов или в материалах конференций.
4.	В открытом интернет-источнике, например в агХгу.
5.	В виде монографии.
А теперь рассмотрим возможности доступа к перечисленным источникам.
Научные журналы, индексируемые реферативными базами и базами цитирования, безусловно, лидируют по возможности ознакомления ученых с размещенной в них информацией. В этой ситуации сильно проигрывают в доступности журналы, которые в таких базах отсутствуют либо вообще не имеют
электронных версий в сети интернет. Вероятность того, что кто-нибудь узнает о результатах, опубликованных в таких журналах, стремится к нулю, если автор не рассылает целенаправленно оттиски своей статьи коллегам или не ссылается на свою же статью в таком недоступном журнале при публикации следующих результатов в более доступном издании.
Тематические сборники статей, как правило, издаются ограниченным тиражом в бумажном виде и оседают на книжных полках самих авторов и их ближайших коллег, и вероятность ознакомиться с тем, что там написано, близка к описанной в предыдущем абзаце для журналов, не имеющих электронной версии в интернете и не индексируемых в базах данных. Изданный тематический сборник в лучшем случае окажется в библиотеках, включенных в список обязательной рассылки издательствами, и его прочитают только те, кто знает о его существовании.
Сборники, издаваемые по материалам конференций, в этом отношении гораздо более доступны, поскольку в большинстве случаев их можно найти в Интернете и они рассылаются всем участникам конференции, т.е. доступны более широкому кругу ученых (если эта конференция более широкого масштаба, нежели конференция молодых ученых отдельно взятого научного учреждения).
Публикация в открытых источниках доступна всем, однако материалы, там публикуемые, в большинстве случаев не проходят серьезного научного рецензирования, и значительно увеличивается вероятность прочитать в этих источниках непроверенную и недостоверную информацию.
В монографиях, как правило, излагается более или менее проверенная временем и опубликованная ранее в журналах или сборниках информация, т.е. большей частью они представляют собой обзор оригинальных собственных исследований, совмещенный с анализом других имеющихся по теме публикаций, являясь, таким образом, вторичным источником полученных авторами научных результатов. По доступности монографии близки к тематическим сборникам, за исключением монографий, издаваемых крупными научными издательства и индексируемых такими базами, как Web of Science (Book Citation Index), Scopus или РИНЦ, наряду с научными журналами.
Таким образом, по доступности информации о результатах научных исследований перечисленные выше источники можно расположить следующим образом:
1.	В открытом интернет-источнике, например в arXiv.
2.	В профильном научном журнале.
3.	В виде тезисов или в материалах конференций.
4.	В виде монографии.
5.	В тематическом сборнике статей.
Поскольку публикация в профильном научном журнале, в отличие от публикации в открытом интернет-источнике, проходит предварительное рецензирование, то для целей оценки научной деятельности этот вид публикации выходит на первое место. Бывают, безусловно, исключения, такие как опубликованное только в arXiv.org сообщение Перельмана, но эти исключения только подтверждают правило.
В целом можно сказать, что наиболее ценными с точки зрения доведения информации до научной общественности являются публикации в изданиях, индексируемых признанными международными базами данных, такими как Web of Science, Scopus, Medline, GeoRef, MathNet и др. Для российских ученых такое же значение приобретает индексация в РИНЦ. Это касается как научных журналов, так и материалов конференций, монографий и продолжающихся изданий - тематических сборников.
Однако большая часть информации во всех перечисленных базах данных относится все-таки именно к научным журналам, составляющим подавляющее большинство в перечнях индексируемых изданий, поэтому все дальнейшие рассуждения будут касаться в основном журнальных публикаций.
Какие чисто количественные библиометрические показатели доступны при проведении анализа результативности НИР с использованием баз данных цитирований?
1.	Количество публикаций конкретного автора, организации, страны и их распределение по журналам и областям знания.
2.	Распределение данных публикаций по годам издания, по соавторам (пофамильно или по организациям и странам), характеризующее научные связи ученого или организации.
3.	Количество цитирований всех статей и каждой статьи отдельно с возможностью просмотра перечня цитирующих статей и их дальнейшего анализа, как в п. 1 и 2.
4.	Указанные сведения дают возможность рассчитать такие показатели, как среднее цитирование статьи ученого (организации, страны) либо за весь период его деятельности, либо за определенные годы, и определить индекс Хирша, соответственно либо общий, либо за определенный промежуток времени.
Может ли любой из этих показателей характеризовать деятельность ученого или научной организации?
Поскольку все указанные параметры по своей природе являются статистическими, то их применимость зависит от размера сравниваемых выборок. Если мы сравниваем библиометриче-ские показатели двух организаций, работающих в одной и той же области примерно одинаковый период времени и сравнимых по количеству работающих в них ученых, то любой из показателей может показать превосходство одной из организаций или их равенство. Однако, если одна из организаций существует 20 лет, а другая 5, или они осуществляют исследования в разных научных областях, или сильно отличаются по количеству ученых, то ни один из показателей напрямую не может использоваться, необходимы либо нормирования, учитывающие как область науки, так и количество авторов, либо выбор каких-либо конкретных промежутков времени с нормированиями, перечисленными выше. Даже в случае прочих равных адекватнее использовать весь комплекс возможных показателей.
1.	При равном количестве статей - разное количество их цитирований, а, следовательно, и разное среднее цитирование одной статьи, может говорить о более высокой востребованности, а следовательно, и уровне статей той организации, у которой выше среднее цитирование.
2.	При равном количестве статей и равном среднем цитировании одной статьи - разные индексы Хирша. Это свидетельствует о том, что в организации с большим индексом Хирша большая доля статей организации хорошо цитируется, следовательно, уровень научных исследований в этой организации выше.
Такие же рассуждения могут быть применимы и в случае сравнения конкретных ученых, только в данном случае сравни-
ваемые выборки значительно меньше и вероятность неправильных выводов, соответственно, выше.
Какой же может быть выход из данной ситуации?
2.2.	СПОСОБЫ СРАВНЕНИЯ ПУБЛИКАЦИЙ В РАЗНЫХ ОБЛАСТЯХ НАУК
Для решения проблемы сравнения разных научных направлений могут применяться различные нормированные показатели. Наиболее ярким примером является использование показателей нормализованного цитирования в наукометрическом аналитическом ресурсе, разработанном Thomson Reuters, под названием InCites [12]. На основе всей совокупности данных о статьях и их цитировании, имеющейся в базах данных Web of Science, проводится расчет средних показателей цитирования статей в конкретном году, опубликованных в конкретных журналах по определенным областям знаний (249 subject categories). Далее проводится анализ каждой конкретной статьи по отношению к полученному значению. Таким образом, если статья, опубликованная в области «PHYSICS CONDENSED MATTER» в 2008 году, цитируется столько раз, сколько в среднем все статьи этой области в этом же году, то нормализированный показатель цитирования этой статьи (или статей организации в данной области в данном году) будет равен 1. При значении больше 1 - уровень выше среднемирового, и соответственно, меньше 1 - ниже. Таким образом, усреднение данных показателей нормализованного цитирования, рассчитанных по годам и областям знаний, может показать, насколько уровень научной деятельности организации соответствует среднемировым аналогичным показателям. Это позволяет сравнивать между собой организации или ученых, работающих в разных областях знаний.
Однако и в данном случае возможны проблемы. Ярким примером этого является последний из опубликованных рейтингов вузов Times Higher Education World University Ranking, в котором МИФИ обогнал лидера рейтинга Калифорнийский технологический институт по показателю нормализованного цитирования благодаря всего двум очень высоко процитированным статьям, соавторами которых в числе более
1000 авторов в коллаборациях оказались сотрудники МИФИ, притом что общее количество статей впервые позволило МИФИ в принципе попасть в этот рейтинг (входной порог -не менее 1000 статей за 5 лет).
Кроме того, оценка российских научных организаций с помощью этого инструмента сильно затруднена из-за того, что только немногим более полутора сотен российских журналов индексируются в Web of Science. Для сравнения - в РИНЦ 7470 российских журналов. В Journal Citation ReportScience - 2795 журналов, издаваемых в США, 557 журналов, издаваемых в Германии, и только 146 российских журналов, в Journal Citation Report - Social Sciences - 1282 журналов, издаваемых в США, 118 журналов, издаваемых в Германии, и только 4 российских журнала. Вследствие этого оценке с помощью инструмента InCites могут подлежать в основном только естественно-научные специальности.
На рис. 1 показано соотношение российских публикаций в базах данных Web of Science. В СПбГУ в 2011 году была введена в действие база данных публикаций, которая в настоящее время представляет собой наиболее полный реестр публикаций универсантов, содержащий более 80 000 записей
о	различных публикациях всех типов по всем областям знаний. Сходство распределения публикаций СПбГУ и России в целом по областям знаний позволяет в какой-то мере экстраполировать анализ публикаций университета на Россию в целом. Сравнение представления публикаций СПбГУ по крупным областям в Web of Science и в базе данных публикаций в ИАС НИД (Информационно-аналитическая система сопровождения научно-исследовательской деятельности Санкт-Петербургского государственного университета), показывает, что большая часть публикаций в области гуманитарных и общественных наук практически недоступна мировому научному сообществу.
Россия,	2008-2012
% ^Science
ÆmrnÊ	H||
jjpP □ Social Science
■Arts&Humanities
96%
Рис. 1. Соотношение российских публикаций 2008-2012 годов в базах цитирований Web of Science (Science - Science Citation Index Expanded, Conference Proceedings Citation Index - Science, Book Citation Index - Science; Social Science - Social Sciences Citation Index, Conference Proceedings Citation Index - Social Science & Humanities, Book Citation Index - Social Sciences & Humanities; Arts&Humanities - Arts & Humanities Citation Index)
Web of Science
(2008-2010)ArtsS
Рис. 2. Распределение публикаций авторов СПбГУ по областям знаний в базе данных Web of Science
ИАСНИД (2008-2010)
Arts & Human
es
25%
Science
52%
Social'
Science
23%
Рис. 3. Распределение публикаций авторов СПбГУ по областям знаний в ИАС НИД СПбГУ
В публикациях в области гуманитарных и общественных наук превалируют статьи в сборниках, большую часть которых не только в Интернете, но и в библиотеках найти и прочитать невозможно, поэтому в первую очередь для более или менее адекватного представления результатов научных исследований в области гуманитарных и общественных наук необходимо переориентироваться, хотя бы частично, на публикации в журналах, желательно международных.
В случае если начатый Минобрнаукой проект «Карта Российской науки» будет реализован, то на основе обобщенной базы публикаций российских ученых в Web of Science и РИНЦ (в который уже несколько лет включаются и публикации, индексируемые Scopus), можно будет достаточно адекватно оценивать по публикационной активности научные учреждения и вузы разного профиля, используя принципы и подходы InCites.
Иной метод сопоставительной оценки публикаций из разных областей знаний предлагает компания Elsevier на основе данных Scopus [11]. Этот метод основан на анализе социтирований (кроссцитирований). Основным в этом способе анализа является принятие условия, что если две статьи цитируют одних и тех же авторов и статьи первых авторов оказываются в списках проци-
тированной литературы одновременно, то эти статьи тематически связаны. На основании такого анализа всего массива публикаций в Scopus выделяется более 70 тыс. кластеров публикаций, наиболее цитируемые из которых (25-40% самых цитируемых для разных уровней анализа) составляют «компетенции», визуализированные в SciVal Spotlight на «колесе науки», которое может быть составлено как для отдельно взятой организации, так и для страны и региона. Чем больше публикаций организации попадают в высокоцитируемые в составленных кластерах, тем больше компетенций выделяется для организации. Поскольку данный метод представляет собой больше качественный, чем количественный анализ массива публикаций, то результат зависит исключительно от наличия и состава публикаций в базе данных Scopus. Вторым способом визуализации данных о публикациях организации (страны) является матричное представление выделенных компетенций, при котором учитываются также тренды развития соответствующих кластеров публикаций - увеличение доли статей организации по отношению к изменению количества статей в мире по данной тематике, изменения в цитируемости по отношению к мировым изменениям. Таким образом, оказывается возможным оценить перспективность направлений исследований, что является крайне важным для стратегического планирования науки. Отличительной особенность SciVal Spotlight является возможность адекватного анализа публикаций в междисциплинарных областях.
2.3.	ОСОБЕННОСТИ ОЦЕНКИ НАУЧНОЙ ДЕЯТЕЛЬНОСТИ ОТДЕЛЬНЫХ УЧЕНЫХ
Оценка труда отдельного ученого по его публикациям, которая теоретически мало отличается от оценки работы лабораторий или институтов, на практике оказывается значительно сложнее хотя бы в силу того, что перестает быть статистическим показателем. Можно сравнить абсолютные значения любого из показателей и констатировать факт, что у ученого А количество статей больше, чем у ученого Б, у ученого Б общее количество цитирований больше, чем у ученых А и В, а ученый В превосходит двух первых по среднему цитированию одной статьи, но это может ничего не значить для реальной оценки труда учено-
го. Ученые А, Б и В могут работать в разных областях знаний, занимать различные должности в научной иерархии, быть разного возраста и все это окажет весьма существенное влияние на их фактические показатели.
На первый план в данном случае выходит правильная постановка цели, с которой проводится оценка.
Рассмотрим несколько модельных случаев.
1.	На конкурс на замещение должности научного сотрудника конкретной лаборатории (или доцента конкретной кафедры) подают заявления 2 соискателя. Сопоставление их библиомет-рических показателей может быть весьма полезным при прочих равных - одинаковом стаже предыдущей работы, одинаковой ученой степени, сходных компетенциях, необходимых для работы в данной должности.
2.	Текущая переаттестация - сравнение библиометрических показателей одного и того же сотрудника за последовательные промежутки времени, динамика показателей.
3.	Сопоставление заявок на получение финансирования -показатели публикационной активности ученых - руководителей или/и исполнителей проекта за весь период их работы и текущих показателей (за период последних 3-5 лет). В данном случае могут быть весьма полезны данные как InCites, так и SciVal Spotlight, если они доступны, поскольку показывают уровень ученых или коллектива ученых по сравнению с мировым уровнем.
4.	Стимулирование публикационной активности - самый сложный случай, поскольку здесь необходимо учитывать одновременно с текущими показателями, такими как количество публикаций за определенный период времени, и какие-либо качественные показатели. Если целью стимулирования ставится просто увеличение количества публикаций, например, в Web of Science или Scopus, то необходимо принимать во внимание принципиальные возможности в написании статей. Установление доплат пропорционально количеству публикаций вряд ли приведет к желаемому результату, поскольку ученый, пишущий, к примеру, 10 статей ежегодно, при установлении сколь угодно больших доплат вряд ли будет физически способен писать их в 2 раза больше, а для сотрудников, имеющих 1-2 статьи в год,
стимулирующий фактор установления доплаты может оказать достаточно большое влияние, при этом общее увеличение количества публикаций организации в Web of Science или Scopus окажется гораздо более значительным. Если ставится задачей увеличить цитируемость статей, то поощрять имеет смысл в первую очередь публикации в высокорейтинговых журналах, потенциальная цитируемость которых больше. В целом достаточно трудно выдержать баланс и провести границу между реальным стимулированием и премированием за выдающиеся достижения, вроде публикации статей в таких журналах, как Science и Nature.
В настоящее время Минобрнаукой провозглашается намерение адресно поддерживать ведущих ученых по конкретным областям наук, и упоминавшийся уже проект «Карта Российской науки» нацелен, в том числе, и на выявление этих самых ученых, достойных адресной поддержки. Вот в этом случае решающую роль могут сыграть именно библиометрические показатели, на основании которых можно определить уровень работы ученого по сравнению с мировыми показателями по данной области. Если использовать, например, такой ресурс как SciVal Spotlight, то это могут быть лидеры имеющихся в России компетенций, развивающихся в соответствии с мировыми трендами (рис. 4), или сочетание хороших значений количества публикаций, средней цитируемости, нормализованной по области знаний цитируемости, индекса Хирша и других показателей, которые можно выяснить в InCites (рис. 5).
По всем вышеописанным показателям - прямым или нормированным - можно выявить лидеров по публикациям как среди ученых, так и среди лабораторий или институтов, однако ответа на вопрос «Можно ли измерить эффективность труда ученого по библиометрическим показателям» это не дает, если понимать эффективность буквально, как приведенное во введении определение самого понятия.
Рис. 4 Представление компетенций России в SciVal Spotlight в матричной форме и в виде «колеса наук»
InGtes™
Calibrate Your Strategic Research Vision
THOMSON REUTEi
Signed In I Incites Home I My Account I Customer Forum I My Datasets I Logout I He
RESEARCH PERFORMANCE PROFILES GLOBAL COMPARISONS INSTITUTIONAL PROFILES FOLDERS
AUTHOR RANKING	Ш 1 I Select an export option j Viewing Dataset: National Citation Report: Russia
Dataset: Na6onal c*360" H“** Time Period: 1990-2013 Subject Areas: cai B,oloGV Thresholds: DocumMM Additional Information: °te this report as InCtesTM, Thomson tortus (2013). ltepcitCreatidl29.01.2013 Data Pircessed 29.11.2012 17:34:23 Data Sc
!:| Abbreviated Names
: I Times Cited
1	SKULACHEV. VF
2	PESTOVA. TV
3	UVERSKY. VN
4	VASILIEV. JM
5	BORISY. GG
6	KISSELEV.L
7	SVERGUN.PI
8	VANIN. AF
9	NEDOSPASOV. SA
10	VINOGRADOV. AD
11	FROLOV. VA
12	ATAULLAKHANOV. FI
13	TKACHUK. VA
14	NEVINSKY. GA
Рис. 5. Скриншот результата формирования пользовательского отчета в InCites (Dataset: National Citation Report: Russia; Report Name: Author Ranking; Time Period: 1990-2013; Subject Areas: CELL BIOLOGY; Thresholds: Citation - 1, Document - 20)
3.	Как измерять эффективность научной
деятельности, используя библиометрические показатели
Если мы понимаем под эффективностью научной деятельности отношение результата к затратам на его достижение, то в случае фундаментальных исследований логичным будет расчет количества публикаций на финансирование исследования, результатом которого стали данные публикации.
Для сравнения эффективности в этом смысле проще всего проводить анализ больших массивов публикаций, например по странам. В данном случае нас не очень сильно заботят ни разнообразие по областям знаний, ни сильно различающиеся абсолютные значения, ни уровень цитируемости. По имеющимся в
открытом доступе данным о расходах на НИР и НИОКР [6] по странам, можно провести сравнение этих данных с количеством публикаций данных стран, например, в Web of Science, и при этом выявляется совершенно четко выраженная корреляция между этими значениями.
Если подсчитать по этим данным, сколько средств необходимо для написания одной статьи, то получается, что в среднем по миру одна статья в Web of Science стоит порядка 950 тыс. долларов США. Естественно, это весьма грубый подсчет, поскольку статьи публикуются не только в журналах Web of Science, достаточное количество средств расходуется на прикладные исследования, по результатам которых осуществляется разработка технологий, на достижение иных результатов. Тем не менее, общее представление эти цифры дают - по 25 странам, лидирующим по затратам на исследования и разработки, «стоимость» статьи в Web of Science варьируется от 310 тыс. долларов США в Швейцарии до 2106 тыс. в Японии. В России этот показатель составляет порядка 840 тыс. долларов США, что весьма близко к среднемировому уровню (таблица 1).
Если мы спустимся на уровень ниже и попробуем таким же образом оценить эффективность работы научно-исследовательского института или вуза, то столкнемся с проблемами, связанными с особенностями публикации результатов исследований в разных областях науки, с проблемами разного направления расходов на собственно проведение НИР в разных областях знаний и другими факторами, т.е. окажется невозможным одним способом оценивать эффективность научной деятельности в естественных и гуманитарных науках, деятельность теоретиков и экспериментаторов.
В этом плане понятие эффективности работы отдельного ученого становится совсем уж загадочной величиной - что считать финансовыми вложениями в работу ученого - только его заработную плату или с добавлением расходов на командировки, на необходимое для работы оборудование и расходные материалы и т.д. Кроме написания статей, у любого ученого есть масса других направлений деятельности, которые нельзя не учитывать при оценке эффективности его работы. Кроме того, если рассчитывать эффективность работы отдельного ученого
по показателям, нормируемым на заработную плату, то российские ученые окажутся самыми эффективными в мире, исключая армянских, поскольку их средняя заработная на втором месте с конца рейтинга и ниже даже, чем в Эфиопии [4].
Кроме того, в случае оценки труда (или его эффективности) при учете публикаций необходимо вводить и качественную составляющую. Если оценка производится за довольно продолжительный период времени, то есть возможность использования показателей цитируемости, индексов Хирша, нормализованной цитируемости и т.д. [2, 3, 5], однако при оценке текущей деятельности (2-3 года) необходимо искать другие подходы.
Рассмотрим только публикационную составляющую интегральной оценки деятельности ученого, понимая, что это далеко не единственный критерий.
Как уже отмечалось выше, для ученых естественнонаучного профиля можно в принципе использовать данные о публикациях Web of Science, хотя довольно большое количество публикуется и в журналах, индексируемых Scopus, но отсутствующих в Web of Science, и в российских научных журналах, не индексируемых международными базами данных. В значительно большей степени это касается ученых, работающих в области общественных и гуманитарных наук, у которых значительно большее количество публикаций в сборниках статей, а для гуманитарных направлений основная доля - монографии.
В связи с этим необходимо разрабатывать какую-либо балльную оценку различных типов публикаций, которая могла бы учитывать и качественную составляющую - статья, опубликованная в высокорейтинговых журналах (как крайний случай -Science или Nature) не может оцениваться так же, как статья в «Вестнике N-ского ун-та», не имеющего импакт-фактора даже в РИНЦ или имеющего 100% самоцитирование.
Естественным в данном случае кажется использовать показатели качества журнала, рассчитываемые библиометрическими базами Web of Knowledge, Scopus [8, 10] или РИНЦ, отражающие до какой-то степени потенциальную цитируемость опубликованных в журналах статей. C тем, что импакт-фактор журнала (либо иной рассчитываемый показатель качества журнала) отражает в среднем качество статьи, в нем опубликованной,
можно спорить, но другого подхода к количественной оценке качества статьи до появления сведений о ее цитировании (кроме чисто экспертной оценки) пока никто не придумал. Этот же подход применялся и для учета статей в научных журналах при расчете ПРНД в Академии наук. Однако основная проблема состоит в несопоставимости показателей, используемых разными базами данных.
Возможно составление раздельных рейтингов по разным видам публикаций с последующим усреднением их результатов или учету каждого из рейтингов с разными весовыми коэффициентами, как это делается при наличии разных показателей в рейтингах университетов. Возможны и другие пути решения этой проблемы.
В Положении о порядке установления доплат за научные публикации в Санкт-Петербургском государственном университете сделана попытка балльной оценки публикаций, учитывающая как уровень журнала, так и область знаний, и количество соавторов [1, 9]. За «показатель качества» журнала берется отношение импакт-фактора журнала в Journal Citation Report к среднему цитированию статей по области знаний из таблицы «Average Citation Rates for papers published by field» раздела Web of Knowledge «Essential Science Indicators». Количество соавторов учитывается по принципу, сходному с используемым при построении Лейденского рейтинга [7].
Для статей в периодических изданиях, имеющих импакт-фактор (далее - ИФ) по Web of Science не менее 0,05, баллы за статью определяются по формуле
баллы = I-RJC,
где I - ИФ периодического издания по Web of Science; C - среднее число цитирований одной статьи по соответствующей области науки за последние 10 лет, взятое из базы Web of Knowledge; R - отношение числа авторов статьи, имеющих аффилиацию с СПбГУ, к полному числу авторов. Если значение величины R получается меньше 0,1, то она берется равной 0,1. Для статей в периодических изданиях, имеющих ИФ по Web of Science менее 0,05 (включая периодические издания базы данных Arts & Humanities, для которых не рассчитывается ИФ), или вообще не индексируемых в Web of Science, но вхо-
дящих в список ВАК или базы данных Scopus и РИНЦ, баллы определяются по формуле с I = 0,05.
Используемый показатель «качества журнала» достаточно хорошо коррелирует с показателем SNIP [8], используемым в Scopus, что позволяет в принципе использовать этот показатель, но количество журналов, для которых он рассчитан, в настоящее время недостаточно для его полноценного использования при всех его преимуществах.
Для журналов, имеющихся в Scopus, но отсутствующих в Web of Science, можно в некотором приближении использовать и показатель SJR [10], который, по крайней мере, для журналов, в которых публикуются авторы СПбГУ и которые присутствуют одновременно в обоих базах, в среднем составляет 0,1 от им-пакт-фактора JCR. Для российских журналов, переводные версии которых индексируются в Web of Science, их импакт фактор, рассчитанный в РИНЦ, почти совпадает с импакт-фактором переводной версии в Journal Citation Report, что позволяет надеяться на то, что со временем можно будет для российских журналов использовать импакт-фактор РИНЦ [1, 9].
Для монографий и глав в монографиях баллы рассчитываются с учетом уровня издательства (что является небесспорным ввиду того, что многие издательства в настоящее время больше волнует коммерческая составляющая, а не качество издаваемой литературы), вклад автора, а также экспертное мнение, выражающееся в наличии рецензий на монографии в ведущих научных журналах или поддержку издания авторитетными научными фондами.
В зависимости от суммарного рейтинга тех публикаций автора за зачетный период 3 года, в которых указан в качестве места работы СПбГУ, формируется рейтинг авторов, используемый при установлении доплат за научные публикации на последующий год.
Таблица 1. Сопоставление расходов на НИР и НИОКР (R&D) и количества статей в Web of Science
в 2011 году по странам
Страна	Расходы на R&D млрд.Ш$'	Доля от мировых расходов на R&D	Количество документов в Web of Science2	Доля от общего кол-ва статей в мире	«Стоимость» статьи, млн. US$
USA	405,3	33,78%	354 486	28,11%	1,143
China Mainland	139,7	11,64%	146 662	11,63%	0,952
UK	38,4	3,20%	97 834	7,76%	0,392
Germany	69,5	5,79%	93 541	7,42%	0,742
Japan	160,3	13,36%	76 099	6,03%	2,106
France	42,2	3,52%	66 283	5,26%	0,636
Canada	24,3	2,03%	57 263	4,54%	0,424
Italy	19	1,58%	53 476	4,24%	0,355
Spain	17,2	1,43%	49 095	3,89%	0,350
India	36,1	3,01%	45 485	3,61%	0,793
South Korea	55,8	4,65%	44 718	3,55%	1,248
Australia	15,9	1,33%	43 441	3,44%	0,366
Brazil	19,4	1,62%	34 210	2,71%	0,567
1	Данные Royal Society [10].
2	Данные InCites.
Таблица 1 (продолжение).
Страна	Расходы на R&D млрд.Ш$1	Доля от мировых расходов на R&D	Количество документов в Web of Science2	Доля от общего кол-ва статей в мире	«Стоимость» статьи, млн. US$
Netherlands	10,8	0,90%	32 975	2,61%	0,327
Russia	23,8	1,98%	28 281	2,24%	0,841
Taiwan	19	1,58%	26 648	2,11%	0,712
Switzerland	7,5	0,63%	24 152	1,92%	0,310
Sweden	11,9	0,99%	20 700	1,64%	0,574
Poland	6,9	0,58%	20 617	1,63%	0,334
Belgium	6,9	0,58%	18 371	1,46%	0,375
Austria	8,3	0,69%	12 496	0,99%	0,664
Israel	9,4	0,78%	12 154	0,96%	0,773
Finland	6,3	0,53%	10 414	0,83%	0,604
Mexico	6,4	0,53%	10 070	0,80%	0,635
1	Данные Royal Society [10].
2	Данные InCites.
Естественно, предлагаемый алгоритм требует доработок, но может служить некоторой базой для разработки методики учета публикаций разных видов, по разным областям знаний, учитывающий как количественные, так и качественные показатели текущей публикационной активности ученых.
4.	Заключение
Из всего вышесказанного можно сделать следующие выводы:
1.	Библиометрические показатели, являясь по своей природе статистическими, хорошо работают на больших массивах публикаций, что позволяет достаточно адекватно сравнивать научную деятельность, например, по странам.
2.	Использование библиометрических показателей на более детальном уровне анализа научной деятельности (деятельность института, подразделения, отдельных ученых) оказывается полезным только в сочетании с другими показателями результативности научной деятельности.
3.	Возможность и способы использования библиометриче-ских показателей для оценки научной деятельности в значительной степени зависит от целей, с которыми проводится оценка и должно сочетаться с другими показателями и экспертной оценкой.
Литература
1.	МОСКАЛЕВА О.В., КАРПОВА М.Э. Оценка публикационной активности сотрудников вуза и пути ее повышения: опыт СПбГУ [Электронный ресурс]. - иЯЪ: http://elibrary.ru/projects/science_index/conf/2012/program.asp (дата обращения 04.07.2013).
2.	ПИСЛЯКОВ В. В. Библиометрия: основные методы и индикаторы. Материалы Научно-практического семинара «Оценка результативности научно-исследовательской деятельности», Казань, 20 октября 2011 г. [Электронный ресурс]. - иЯЬ: http://elsevierscience.ru/events/ kazan2011/schedule/ (дата обращения 04.07.2013).
3.	FALAGAS ME., KOURANOS V.D., ARENCIBIA-JORGE R., KARAGEORGOPOULOS D.E. Comparison of SCImago journal rank indicator with journal impact factor // FASEB. -2008. - №22. - P. 2623-2628.
4.	GUTTENPLAN D.D. How Much Is a Professor Worth? - The New York Times, Published: April 2, 2012. - [Электронный ресурс]. - URL: http://www.nytimes.com/2012/04/02/ world/europe/02iht-educlede02.html?_r=2&pagewanted=all& (дата обращения 04.07.2013).
5.	HIRSCH J.E. An index to quantify an individual's scientific
research output // PNAS. -	2005.	-	№102(46).	-
P.16569-16572.
6.	Knowledge, networks and nations. Global scientific collaboration in the 21st century. - London: The Royal Society, 2011. -113 p.
7.	Leiden Ranking. Methodology. [Электронный ресурс]. - URL: http://www.leidenranking.com/methodology.aspx (дата обращения 04.07.2013).
8.	MOED HENK F. Measuring contextual citation impact of scientific journals // arXiv:0911.2632. - URL: http://arxiv.org/ abs/0911.2632 (дата обращения 04.07.2013).
9.	MOSKALEVA O., DMITRIEVA Yu. Application of Scien-tometrics in University evaluation and research policy: foreign experience and Russian practice // Geomatics and Information Science of Wuhan University. - 2012. - Vol. 37 - P. 17-20.
10.	SCImago. SJR - SCImago Journal & Country Rank // Retrieved July 18, 2011. [Электронный ресурс]. - URL: http://www.scimagojr.com (дата обращения 04.07.2013).
11.	SciVal Spotlight. - URL: http://info.scival.com/spotlight (дата обращения 04.07.2013).
12.	Research Evaluation and Objective Analysis of Your People, Programms and Peers. -
URL: http://researchanalytics.thomsonreuters.com/incites/ (дата обращения 04.07.2013).
IS IT POSSIBLE TO EVALUATE RESEARCHER’S WORK USING BIBLIOMETRIC INDICATORS?
Olga Moskaleva, Saint-Petersburg State University, Cand.Sc., ([email protected]. ru).
Abstract: Basic bibliometric indicators and their usage for research activities evaluation are reviewed. Special attention is paid to the particular features of bibliometric indicators application at different levels of analysis - at the level of a country, an organization, an individual researcher - and to the use of analytical tools InCites and SciVal Spotlight for research benchmarking. The problems of research activities performance assessment are discussed.
Keywords: research results, efficiency, bibliometrics.
Поступила в редакцию 01.02.2013.
Опубликована 31.07.2013.
